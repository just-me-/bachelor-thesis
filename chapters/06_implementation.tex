\section{Implementation}
This chapter describes the implementation of the planned design.
First, the characteristics of the client are shown.
Then, basic components of the server are described.
The symbol table and its properties are treated as a separate section.
The resulting features follow.
This is followed by a discussion of platform independence followed by a section about automated testing.
Results of our usability test and the resulting conclusions and improvements follow.
This chapter is closed by the success achieved in terms of continuous integration.

\subsection{Client}
The implementation of the client could basically be done as intended.
The whole code could be broken down into the individual components defined in the design phase.
Individual deviations and descriptions of the individual implementation concepts follow in this section. \\

These include a better separation of the components,
a simplified migration concept for other, future IDEs,
the download of the langauge server
as well as basic configurations which are made possible for the end user.

\subsubsection{Better Encapsulation Through Interfaces and Modules}
\label{section:implementation:client:module_encapsulation}

During the implementation process, many confusing module imports and component usages arose.
Their purpose was generally unclear and thus difficult to understand.
The imports caused a lot of dependencies, too.
This problem had to be solved by further introductions of interfaces and encapsulation of modules. \\

Although interfaces were used for individual types,
core components did not use their own interfaces.
To reduce coupling, isolated modules were formed in a comprehensive refactoring process.
The modules now no longer program on the class implementations, but against the interface. \\

For this purpose one importable module with the name \code{\_<Directory>Modules} was created for each directory.
Figure \ref{fig:client_2nd_refactoring} shows an overview of the interfaces.
In addition, the dependencies among each other are shown.
For simplicity, the contents of \code{stringRessources} and \code{typeInterfaces} to each package have been omitted.
The dependency of \code{extensions} on VS Code is based on dependeny injection and represents the plugin entry point.
Apart from this dependency, no dependency injection dependencies are shown in the diagram. \\

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{client_2nd_refactoring.png}
    \caption{Second Major Client Refactoring}
    \label{fig:client_2nd_refactoring}
\end{figure}

At first glance, the architecture appears much tidier.
The dependencies are now pointing from top to bottom.
Methods have been simplified and the number of parameters could be reduced significantly.
Component identifiers have been renamed to be more understandable. \\

However, it is now also noticeable that there are considerably more dependencies on \code{stringRessources}.
While in the previous version only the module \code{ui} used \code{stringResources}, it is now used by almost all other modules.\\

This has the following reason: Up until this refactoring, the task of \code{stringResources} was to be a central collection of all UI strings. \glsadd{UI} \intnote{is das glossar? dann msÃ¼ste es ja eig midnetsens ui anzeigen :O}
In the code review, it was decided that default values should no longer be set within the independent modules,
but rather at a central location.
This would make it easier to maintain these values.

\subsubsection{Client Modules in Detail}
The individual modules from the design concept are shown below.
The components shown in green are exported to the outside of the module and can be used by other modules.
The other, orange components are only used within the module. \\

For simplicity, constructors, private methods and private variables are omitted in the diagrams.
Class implementations of interfaces only implement the methods specified in the interface as public.
For this reason, their contents are not displayed for clarity. \\

In addition, there are two core modules, which were not considered in the design concept.
The need for these modules only became apparent during the implementation phase.
This concerns the isolation of VS Code components
and the download of the Dafny language server.
These two modules will be discussed separately in the following sections and not in this section. \\

\textbf{\code{dafnyLanguageServerStartup}}\\
The main module \code{dafnyLanguageServerStartup} is used by the \code{extension.ts}
and contains basicly the plugin's "main logic".
It is to start the Dafny language server and establish a connection,
as well as basically initialize the plugin. This includes creating the UI management component and command registrations.

If no local language server is available, the language server is downloaded from a server \\
using the \code{LanguageServerInstaller} component.
This component is only used inside the package, and is not exported to the outside,
as can be seen in the figure \ref{fig:placeholder_ref}.
This component can also be used to update the language server locally.
Update means in this case to delete the local existing language server and download the latest version.
For more details see section \ref{section:implementation:client:download}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{implementation/dafnyLanguageServerStartup}
    \caption{Module \code{dafnyLanguageServerStartup}}
    \label{fig:placeholder_ref}
\end{figure}

The logic of the main component \code{serverInitializer} itself was kept relatively small.
To start the language server as a local process, two steps are basically required:\\

First, basic options are set for the language server.
These options are set in the \code{serverOptions} component. This component implements the \code{LanguageClient}
of VS Code. "Client" is somewhat confusing in that sense, since this module is used to connect the language server; from client side.
Among other things, the options are set with which command the server is started and which file types, which are opened in VS Code by the user of the plugin, should be transferred to the server. \\

Secondly, \code{serverInitializer} registers a callback as the program entry point to the created \code{serverOptions} instance
and then the language server is started with \code{this.languageServer.start()}.
To run the Dafny language server, an instance of \code{DafnyRunner} is created.
This component is part of the \code{localExecution} package.\\

\textbf{\code{ui}}\\
This package is responsible for all visual representations.
This includes the status bar information and the display of the CounterModel.
Also it registers VS Code commands and context menu additions. \\

\code{DafnyUiManager} is the basic UI entry point and manages the UI components.
It creates the individual components and updates them specific events if necessary.
This is the case, if the opened document is changed by the plugin user.\\

Also a \code{disposeUi} function is also provided, which destroys the UI elements. This is for example
on a Dafny language server restart the case. On restart all, UI components are rebuilt,
so that a clean plugin restart is also performed in the client if one of the features should
be frozen and does not response anymore in an extreme case.\\

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{tmpPlaceHolderTodo}
    \caption{Commands in the Context Menu and the VS Code Command Line}
    \label{fig:commands}
\end{figure}

The \code{Commands} package registers all commands that are offered to the user
and links them to corresponding callback functions.
These commands are available with the context menu
and the available commands in the VS Code Command line, as shown in Figure \ref{fig:commands}.
Individual dependencies are injected. Thiese includes:
\code{IDafnyRunner} to call compile and run as a callback as you can see for examle in listing \ref{lst:compileAndRun}.
Furthermore \code{IDafnyUiManager} is injected
in order to access the CounterModelProvider with the appropriate commands and to show or hide it.

\begin{lstlisting}[language=typescript, caption={Excerpt from \code{commands.ts}}, captionpos=b, label={lst:compileAndRun}]
[..]
name: CommandStrings.CompileAndRun,
callback: () => {
  const compile: ICompile = new Compile(this.languageServer);
  compile.compile(false).then(() => compile.run(this.runner));
}
[..]
\end{lstlisting}

The following commands are registered:
\begin{itemize}
    \item {\bf Compile} \textendash{} to compile the Dafny program.
    \item {\bf Compile with Custom Arguments} \textendash{} to pass a compilation request with user-specific
    compile parameters to the server.
    \item {\bf Compile and Run} \textendash{} after compiling the dafny program is executed and the output is displayed.
    \item {\bf Show CounterExample} \textendash{} displays the CounterExample for the currently opened Dafny file, if available.
    \item {\bf Hide Counter Example} \textendash{} hides CounterExample for the current dafny file.
    \item {\bf Show References} \textendash{} with a click on a CodeLens references,
    the references are shown to the user via a popup window.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{tmpPlaceHolderTodo}
    \caption{Warning Message Received From Server (zB von GoTo bei invalidem File)}
    \label{fig:msg_example}
\end{figure}

The \code{Notifications} component is responsible for displaying messages received from the server to the user.
There is an example shown in figure xxx.
There are the following three types, each of which is displayed with a different color:

\begin{itemize}
    \item {\bf Error} \textendash{} is shown in red.
    \item {\bf Warning} \textendash{} is displayed in yellow.
    \item {\bf Info} \textendash{} is shown in blue.
\end{itemize}

The logic of the display messages is provided directly by the VS Code API.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{implementation/ui}
    \caption{Module \code{ui}}
    \label{fig:ui_module}
\end{figure}

The \code{provider} module provides the individual UI components.
The packages are exported to be used by the \code{DafnyUiManager} component.
However, the providers module is not exported to the outside by the \code{ui} module,
so it is shown in orange inf figure \ref{fig:ui_module}.
The module was created purely for grouping and a better file structure.\\

The \code{CodeLensProvider} component is very simple. CodeLens data transferred from the server is transferred to the VS Code API.
The logic is limited to passing the data through. The actual display of the CodeLens popup window is done via the
VS Code API. More about the logic of CodeLens can be found in section \ref{section:implementation:features:codelens}. \\

The \code{CounterModelProvider} component is used to display and hide CounterModels.
This component also stores in which Dafny files a CounterModel should be displayed and in which not.
Therefore, if the user changes the opened file in the worspace, the CounterModel is automatically hidden or shown.
The CounterModuel supports a dark and light mode as shown in figure \ref{fig:dark_light_mode}.
This mode is automatically set accordingly,
depending on whether VS Code is set to light or dark by the user.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{tmpPlaceHolderTodo}
    \caption{CounterModel in Dark (Left) and Light Mode (Right)}
    \label{fig:dark_light_mode}
\end{figure}

Unlike the Compile feature, the \code{CounterModelProvider} creates a callback and passes it to the \code{serverRequest} module.
Therefore an update-call of the \code{CounterModelProvider} requires a transfer of the language server instance to instantiate a \code{RequestCounterExample}.
This is for the following reason: Unlike the \code{StatusbarProvider} or the \code{CodeLensProvider},
\code{CounterModelProvider} has an active influence on it,
when a server request should be sent and when not.
With the components for the statubar and CodeLens react passively to an event.

In this way the \code{CounterModel} component can regulate the server requests.
For reasons of efficiency, the implemented client-side display of CounterModels limits its
server requests to a certain number per second.
This means that even if a plugin user types very fast on the keyboard, a
update requested by \code{CounterModelProvider} to the server is limited by default to two per second. \\

The \code{StatusbarProvider} reacts to messages from the Dafny language server.
It primarily displays the following information to the user as shown in figure \ref{fig:statusbar}:
Whether the Dafny file is valid, if how many errors are present and the Dafny language server version.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{tmpPlaceHolderTodo}
    \caption{Dafny Statusbar}
    \label{fig:statusbar}
\end{figure}

\textbf{\code{serverRequests}}\\
This package is responsible for server requests which are not automatically handled by the VS Code.
Specifically this concerns the LSP extensions for the compilation of Dafny programs and the CounterExample
as shown in figure \ref{fig:serverRequests}.

Both components receive an instance of \code{LanguageClient} injected to gain access to the server.
As explained for the component \code{RequestCounterExample},
the CounterExample feature limits the server requests.
Therefore only one instance of this component is generated and injected callbacks are used.
 is executed each time the user explicitly requests a compile.
A new instance of \code{Compile} is created each time.
Therefore, an asynchronous method is used for this component.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{implementation/serverRequests}
    \caption{Module \code{serverRequests}}
    \label{fig:serverRequests}
\end{figure}

\textbf{\code{localExecution}}\\
This package is used for the local execution of programs.
For example to execute \code{.exe} files.
For macOS and Linux these are executed using mono.
This module takes care of the correct execution of compiled Dafny programs
and of the Dafny language server, which is also an \code{.exe} file.\\

\code{ExecutionCapabilities} check for supported capabilities.
Under Windows \code{.exe} files can be simply executed.
Under macOS and Linux the mono version is checked and if necessary the user is asked to install mono. \\


Die Komponente xxx fÃ¼hrt kompilierte Dafny programme aus. Sie erstellt einen entsprechenden Terminal Prozess,
fÃ¼rt das Program aus und zeigt dem Benutzer die entsprechende Ausgabe dar. Diese Komponente wird von
\code{Compile} verwendet. NatÃ¼rlich wird gegen das jeweilige Interface programmiert, wie sie in Figure xx dargestellt sind.

The component \code{DafnyRunner}  executes compiled Dafny programs.
It creates a corresponding terminal process
for the program and shows the user the corresponding output.
This component is used by \code{Compile}.
Of course, programming is done against the respective interface, as shown in figure \ref{fig:localExecution}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{implementation/localExecution}
    \caption{Module \code{localExecution}}
    \label{fig:localExecution}
\end{figure}

\textbf{\code{typeInterfaces}}\\
Special TypeScript type extensions,
as they are used for the return values of server requests
that are not contained in the LSP, are defined in interfaces.
This concerns the return types of compile and CounterExample as shown in figure \ref{fig:typeInterfaces}.

In principle, there is a type interface for the arguments and for the results for each own implemented LSP feature.
Only for CodeLens the types are somewhat more complex, which is why a different grouping was created for this interface.
\code{ICodeLensReferences} is a file, which contains several interfaces and no own module.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{implementation/typeInterfaces}
    \caption{Module \code{typeInterfaces}}
    \label{fig:typeInterfaces}
\end{figure}

\textbf{\code{stringResources}}\\
All string resources are stored in this module.
They are logically grouped by usage area, as shown in figure \ref{fig:stringResources}.
Contrary to the design, this module does not only contain UII messages displayed to the user as mentioned in section
\ref{section:implementation:client:module_encapsulation},
but is the central outsourcing of all strings that also have to do with configurations.
For example which file extensions Dafny files have.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{implementation/stringResources}
    \caption{Module \code{stringResources}}
    \label{fig:stringResources}
\end{figure}

The structure consists of exported classes with static members. For simplicity, these members are not listed in the figure.
In listing \ref{lst:stringResourcesExample} is an example.

\begin{lstlisting}[language=typescript, caption={Excerpt from class \code{LanguageServerNotification}}, captionpos=b, label={lst:stringResourcesExample}]
export class LanguageServerNotification {
  public static Error: string = "ERROR";
  public static Warning: string = "WARNING";
  public static Info: string = "INFO";
[..]
\end{lstlisting}

\subsubsection{Encapsulation of the VS Code Components}
 \intnote{todo auch implementieren wie beschrieben :P}

During our implementation of the client we noticed that almost all our modules require different modules of VS Code.
For example, the UI components needed different graphical elements while console processes are used to execute Dafny files.
So the whole plugin had dependencies on the VS Code specific module kit,
which could not be offered by other IDE's in the same way. \\

Because we wanted to design our plugin for VS Code in a way that the migration for other plugins
for other IDE's is as easy as possible, we wrote additional module \code{ideApi} as shown in figure \ref{fig:packageIdeApi}.
From this module the modules used by VS Code are exported with neutral names.
All modules except \code{typeInterfaces} and \code{stringResources} use this module directly or indirectly.
The idea here is that when migrating to another IDE, adapter components can be written in module \code{ideApi}
for the VS Code modules used in a centralized way.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{tmpPlaceHolderTodo}
    \caption{Module \code{ideApi}}
    \label{fig:packageIdeApi}
\end{figure}

However, we have not already implemented our own adapter classes and interfaces in our refactoring.
This has the following reason:
Through this encapsulation, developers ideally only need to make changes in a central location to migrate the plugin to another IDE.
In the worst case, however, he will have to reimplement the entire client code.
This means, it depends on the IDE for which a new Dafny plugin should be developed.
It depends on the IDE for which a new Dafny plugin should be developed,
and if TypeScript is supported by this IDE as plugin development or not.\\

In our thesis we did not analyze with which other IDEs support which form of plugin development for language server connections.
For example, for the plugin development for atom JavaScript \cite{plugin-atom} can be used,
while for Eclipse mostly Java \cite{plugin-eclipse} is used.

\subsubsection{Download of the Dafny Language Server}
\label{section:implementation:client:download}
Since the original Dafny plugin included the language server (which was written in TypeScript) in the plugin itself,
we assumed in the design phase that we could integrate our new Dafny language server directly in the plugin too
and deploy it in to the plugin markedplace. \\

During the implementation we noticed that this would be an unpleasant solution.
In the Dafny project - where our language server will be integrated - builds
are created per operating system during releases \cite{dafny_lang_builds}.
So we would have to install the builds for all platforms in our plugin,
which would make little sense.
Windows users would download macOS builds additionally and macOS the windows version as shown in figure \ref{fig:dafnyReleaseVersions}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{implementation/dafnyReleaseVersions}
    \caption{Dafny Release 2.3.0 Builds as Example}
    \label{fig:dafnyReleaseVersions}
\end{figure}

Furthermore, it would have been impossible for us to update client and server independently of each other in the future.
Therefore the language server is now downloaded by the client.
Each time the language server is started or restarted within the client,
it checks whether the latest version is installed.
If not, the local Dafny language version is removed and the latest version is downloaded. \\

Therefore the original TypeScript code of the old language server,
which had downloaded the Dafny client, was analyzed \ref{fig:ts_dafny_installer}.
From this we have implemented the core functionality in a clean interface: \code{ILanguageServerInstaller}.
Since our Language server is not yet integrated into the official build,
we have implemented our own, temporary implementation of the downloader as \code{LanguageServerInstaller}.
As soon as our Dafny language server is integrated in the Dafny project,
the component can easily be replaced, because the plugin components program against the interface.
Minimal adjustments are required to replace the component. In some cases, more suitable names were chosen for methods in the interface.

\subsubsection{Customizable Through Configuration}
There are basically two gradations of configurations.
First, there are the configurations for developers in the \code{stringResources} component.
This includes for example Dafny file extensions and other configurations which are not to be changed directly by the user.

Secound, there are the user configurations, which can be changed by the plugin user via the settings of VS Code.
In the figure \ref{fig:settings} the configurations offered to the user are listed.
There is an extract of the plugin description, which can be seen by users in the plugin marketplace.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{implementation/settings}
    \caption{Part of the Plugin \code{README.md}}
    \label{fig:settings}
\end{figure}

For example the colors of the displayed CounterExample can be changed or other compile arguments can be set for Dafny as default.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Server}
In this section, the server implementation is discussed.
Just as in the Design-chapter, the server structure will be analyzed from top to bottom, starting from the \code{Main}-method and ending at the utility layer.
The implementation of the symbol table is split into a separate section.

\subsubsection{Server Launch}
The server starts by executing the \code{Main} method.
As done in common practice, it is kept very short.
All it does is launching the language server, which is already handled by another class.
The full \code{Main}-method is shown in listing \ref{lst:mainserver}.

\begin{lstlisting}[language=csharp, caption={Main Function}, captionpos=b, label={lst:mainserver}]
public static async Task Main(string[] args)
{
    DafnyLanguageServer languageServer = new DafnyLanguageServer(args);
    await languageServer.StartServer();
}
\end{lstlisting}

The launch of the server itself is divided into four stages.
First, preparational work is done.
This happens already in the constructor of the language server.
Preparation includes
\begin{itemize}
    \item Reading and processing config variables
    \item Setting up the logging framework
\end{itemize}
Secondly, the actual server is launched.
The logger will directly be injected and all handlers are registered.
In the third stage, once the server is running, a message sending service is instantiated to notify the client about the successful server start and, if any, errors occurred during start up.
Lastly, the console output stream is redirected to keep the language server stream isolated.
The constructor and the \code{StartServer}-method are partially shown in listing \ref{lst:serverstart}.

\begin{lstlisting}[language=csharp, caption={Starting the Language Server}, captionpos=b, label={lst:serverstart}]
public class DafnyLanguageServer{
    public DafnyLanguageServer(string[] args)
    {
        var configInitializer = new ConfigInitializer(args);
        configInitializer.SetUp();
        configInitErrors = configInitializer.Errors;
        log = LoggerCreator.GetLogger();
    }

    public async Task StartServer()
    {
        log.Debug(Resources.LoggingMessages.server_starting);
        server = await LanguageServer.From(options => options
            .WithHandler<TextDocumentSyncTaskHandler>()
            .WithHandler<RenameTaskHandler>()
            ...
        );
        ExecutePostLaunchTasks();
        await RedirectStreamUntilServerExits();
        log.Debug(Resources.LoggingMessages.server_closed);
    }
}
\end{lstlisting}

\subsubsection{Handler}
Handlers are passed to the language server and are called whenever the language server receives a corresponding request.
Services, such logging or workspace management, can be injected and are thus available for the handler.
As discussed in chapter \ref{chapter:design}, handlers are based around a \code{Handle} method.
For example, every time the server receives a \code{textDocument/Definitions} request, this \code{Handle} method will be called.
The parameter and return types are specific per request.
GoToDefinition would pass a text document location as input, namely the cursor position, and it expects a \code{LocationLink} as response,
namely where the cursor should jump to.
Own requests can be realized according to section \ref{chapter:customlspmsg} by defining an own interface.\\

All handlers require two additional methods, aside the actual \code{Handle}:
\begin{itemize}
    \item GetRegistrationOptions: This method is called when the handler is registered.
    It allows to set options at the time the server is started.
    Such an option is for example after which characters AutoCompletion should be automatically triggered.
    \item SetCapability: It allows to set handler-specific capabilities, such as if the rename-handler will also support a 'prepare rename' feature.
\end{itemize}

A lot of code for these classes is always identical and was thus extracted to a generic base class.
This concerns for example the creation of a logger out of the logger factory or handling of errors.\\

To keep all of this separated from the actual tasks, it was targeted to just forward the request to a core-provider.
This could be well achieved.
Many handlers look just as shown in listing \ref{lst:handlecompilation}.

\begin{lstlisting}[language=csharp, caption={Handling Compilation}, captionpos=b, label={lst:handlecompilation}]
public async Task<CompilerResults> Handle(CompilerParams request, CancellationToken cancellationToken)
{
   _log.LogInformation(string.Format(Resources.LoggingMessages.request_handle, _method));
   try
   {
       FileRepository f = _workspaceManager.GetFileRepository(request.FileToCompile);
       return await Task.Run(() => f.Compile(request.CompilationArguments), cancellationToken);
   }
   catch (Exception e)
   {
       HandleError(string.Format(Resources.LoggingMessages.request_error, _method), e);
       return null;
   }
}
\end{lstlisting}

The file to compile is given as an argument.
The corresponding repository can be requested from the \code{WorkspaceManager}, which is injected to all handlers.
The request is then forwarded to the according provider, which will calculate the results.
All information required, such as the precompiled program, are available from within the \code{FileRepository}.
In case of an error, a message is sent to the user and the error is logged within the \code{HandleError} method.\\

Some handlers take additional actions, such as awaiting the result of the provider, and then sending user feedback according to the outcome.
This is done with GoToDefinition for example.
If the request was triggered at a declaration, an additional user message is sent.
By handling all communication with the handler, the message sending service does not have to be passed downwards to the core logic component.


\subsubsection{Core}
Within this package, the result of a request is assembled.
While it may sound like complex logic is happening here, it turned out that for most cases, all information is just available by the symbol table.
Consider the example of GoToDefinition.
A code excerpt is shown in listing \ref{lst:gotoProvierExample}.
As you can see, the actual task of finding the definition is resovled by the symbol table engine and just available as a property.
The actual task just considers the assembly of the correct result wrapper class.

\begin{lstlisting}[language=csharp, caption={GoToDefinition, Core Provider}, captionpos=b, label={lst:gotoProvierExample}]
ISymbol symbolAtCursor = _manager.GetSymbolAtPosition(uri, line, col);
ISymbol originSymbol = symbolAtCursor.DeclarationOrigin;

var position = new Position((long)originSymbol.Line - 1, (long)originSymbol.Column - 1);
var range = new Range { Start = position, End = position };
var location = new Location { Uri = originSymbol.FileUri, Range = range };

List<LocationOrLocationLink> result = new List<LocationOrLocationLink>();
result.Add(new LocationOrLocationLink(location));
return new LocationOrLocationLinks(result);
\end{lstlisting}

There are a few features that had to be extended with more complex logic.
These are described in section \ref{section:imp:features}

\subsubsection{Workspace}
The workspace is a component representing any opened files by the client.
Thus, it naturally consists only of a single property.
This is a dictionary, mapping a file-location to an internal file-representation:

\begin{lstlisting}[language=csharp, caption={Workspace Property}, captionpos=b, label={lst:workspaceproperty}]
private readonly ConcurrentDictionary<Uri, FileRepository> _files;
\end{lstlisting}

It offers methods to retrieve files and to update them.
Since updates can be down in two different kinds, incremental or full, the update method is overloaded for both cases.
The update requests are forwarded to the class \code{FileRepository}, which is used as the internal representation of a file.
It of course contains the source code.
However, this is not done directly as a string property, but wrapped in a class \code{PhysicalFile}.
Thus, the actual representation on the hard disk is separated even further.
The \code{PhysicalFile} class can then also take responsibility for applying file updates.\\

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{implementation/workspace.png}
    \caption{WorkspaceManager and FileRepository}
    \label{fig:worksapceAndRepo}
\end{figure}

Aside the file content, each \code{FileRepository} will also contain \code{TranslationResults}.
\code{TranslationResults} is a wrapper class for anything provided by the Dafny backend:
\begin{itemize}
    \item Could the file be parsed?
    \item Could it be verified?
    \item Is it logically correct?
    \item What errors and warnings occurred?
    \item How far could it be compiled?
    \item What internal compilation results could be produced for later reuse?
\end{itemize}

Last but not least, the newly implemented symbol table is also attached to the file repository.
To obtain all of these results, the class simply invokes the \code{SymbolTableGenerator} and the \code{DafnyTranslationUnit}.
Thus, all information about a file is accessible from within the file repository.


\subsubsection{DafnyAccess}
Dafny Access it the package invoking the Dafny backend to obtain verification results.
The core class in this package is the \code{DafnyTranslationUnit}.
It was partially taken over from the pre-existing projects, but as part of this bachelor thesis it was refactored and simplified.\\

\begin{figure}[H]
    \centering
    \includegraphics[width=12cm]{implementation/DTUSeq.png}
    \caption{WorkspaceManager and FileRepository}
    \label{fig:DTUSeq}
\end{figure}

In the constructor, the translation unit accepts a \code{PhysicalFile}.
The class then offers a single public method \code{public TranslationResults Verify()}.
Within the method, the following sequence of events as illustrated in figure \ref{fig:DTUSeq} occurs:

\begin{enumerate}
    \item It is checked that the instance has never been used before.
    This is, since the error reporter must be empty.
    Otherwise, errors would be reported multiple times.
    \item Next, Dafny is configured.
    This includes the registration of the Dafny error reporter and setting any options to default.
    The only non-default option is that the engine is supposed to generate a model file, which can later be used for CounterExample calculation.
    The configuration is shown in \ref{lst:setupdafnyoptions}.
    \item The Dafny parser is called.
    This step will report any syntax errors.
    \item The Dafny Resolver is called, if parsing was successful.
    This step will do semantic checks, such as type checks.
    A \code{DafnyProgram} results upon success.
    \item If successful, the precompiled \code{DafnyProgram} will be split into \code{BoogieProgram}s.
    \item The Boogie Execution Engine is invoked to perform logical correctness checks on the \code{BoogieProgram}s.
    \item Any errors that were reported are collected, converted and provided in the field \code{\_diagnosticElements}
    \item All results are wrapped by the \code{TranslationResult} class, providing the diagnostics, the Dafny program and the boogie programs.
    Also, within the property \code{TranslationStatus}, it is remarked how far the verification and translation process succeeded.
\end{enumerate}


Note in the following snippet, that dafny options are by directly calling Dafny's backend.
\begin{lstlisting}[language=csharp, caption={Setting up Dafny Options}, captionpos=b, label={lst:setupdafnyoptions}]
    private void SetUpDafnyOptions()
    {
        DafnyOptions.Install(new DafnyOptions(_reporter));
        DafnyOptions.Clo.ApplyDefaultOptions();
        DafnyOptions.O.ModelViewFile = FileAndFolderLocations.modelBVD;
    }
\end{lstlisting}





\subsubsection{Utilitites}
The bottom layer of the project is formed by the utiltiy layer.
It contains three packages
\begin{itemize}
    \item Tools
    \item Commons
    \item Resources
\end{itemize}
\code{Commons} contains classes that are used within multiple parts of the code, such as \code{TranslationResults} and were already discussed.
\code{Resources} contains string resources and were realized with \code{.resx} files.
Within the \code{Tools} package,
a variety of services can be found that do not necessarily directly correspond to Dafny,
but are useful within the language server environment.\\

\textbf{Config Initializer}\\
This class is used prior to the server launch and initializes a few config settings.
The settings are stored within the static class \code{Commons/LanguageServerconfig.cs}.
The config initializer will first of all set hard coded default values to avoid any kind of null pointer exceptions.
Afterwards, the file \code{Config/LanguageServerConfig.json} is parsed with Newtonsoft's Json.NET library \cite{jsondotnet}.
Any available values will be written to the static configuration class.
Unknown or illegal values will not be set and errors are added to an error reporter.
Finally, the launch arguments are parsed, again overwriting the config settings if applicable or reporting errors otherwise.
A simple argument parser was implemented manually.
Alternatively, a library could have been used for this task such as \cite{clparser}.
The config initializer is implemented exception safe.
This will run to completion and at worst just provide default values.
Errors can later be extracted from the \code{ErrorReporter}.
Each task is done by a dedicated component.\\

\textbf{LoggerCreator}\\
This class simply sets up a \textit{Serilog} \cite{serilog} logger.
For this purpose, the following information is extracted from the \code{LanguageServerConfig}:
\begin{itemize}
    \item Minimum loglevel
    \item Path of the logfile
\end{itemize}

\textbf{MessageSenderService}\\
This is a simple class accepting a \code{ILanguageServer} in the constructor.
Afterwards, it provides methods to send notifications to the client.
Similar to logging, methods for each severity level are available, such as \code{public void SendError(string msg)}.\\

\textbf{ReservedWordsProvider}\\
This is a class providing a set of words, that are not suited for identifiers.
This is, for example, 'method', 'class', or 'return'.
The class tries to read and parse \code{Config/ReservedDafnyWords.json}, which can be user adjusted in case the Dafny specification changes.
If the file cannot be read or has a wrong format, a hard coded default list is used which was taken out from the Dafny Reference Manual \cite{dafnyReferenceManual}.
A HashSet was used to provide fast access to the set.\\

While this component is specifically used solely for the \code{rename}-Feature, it was extracted to be also available at other spots if required for future features.



%%%%FUCK IST DAS LANG!!!!







\subsection{Symbol Table}
This chapter describes the implementation of the symbol table.
The symbol table was designed to handle four different tasks:

\begin{itemize}
    \item Providing Symbol Information
    \item Symbol Table Generation
    \item Symbol Table Navigation
    \item Symbol Table Management
\end{itemize}

\subsubsection{Symbol Information}
Obtaining information about a symbol was realized by a wrapper class.
Logic was extracted from this class as far as possible to keep it short and concise.
As we have seen in chapter \ref{chapter:design}, this class needs to contain a lot of properties.
The most important properties are:
\begin{itemize}
    \item Name
    \item File
    \item Position in File
    \item Body Location, if any
    \item Kind and Type
    \item Link to Parent Symbol
    \item Link to Declaration Symbol
    \item Hash with all Children Symbols (Only Declarations)
    \item List with all Descendants (Any symbol occurring in the body)
    \item List with all Usages of the symbol
    \item BaseClasses
    \item Parameters
    \item The associated module
    \item Link to the associated default class for quick access.
\end{itemize}

The provided properties are supposed to facilitate working with the symbol tree.
For example, if a symbol's definition cannot be found with regular methods,
the property with the associated default class can be accessed to search the symbol there.
No separate logic to find the default class is necessary.
This is advantageous, since the default class is in the global namespace and not a direct ancestor of a symbol.\\

To enable efficient access to the children of a symbol, we have opted for a key-value data structure.
The key is the child symbol's name, the value the actual \code{SymbolInformation} object.
This hash structure enables access to a child symbol with a runtime of $O(1)$.
For example, if a module \code{M} contains a class \code{C}, and within the class there is a method \code{foo},
one can simply start from the root symbol and navigate through the hash maps in constant time.
The \code{[]} operator was overloaded to make this as convenient as possible:\\
\code{rootSymbol["M"]["C"]["foo"]}.\\

Technically, the symbol table is more of a double linked tree, then a table.
To be consistent, the structure will be called symbol table.\\

While this is very fancy, the convenience comes at a price.
Many properties do not apply for all kinds of symbols.
Consider the following code segment:

\begin{lstlisting}[language=dafny, caption={Example Code Regarding Symbol Information}, captionpos=b, label={lst:aldbkajds}]
method foo() {
    var x := 5;
    print x;
}
\end{lstlisting}

The symbol \code{foo} profits by almost all properties.
It can have children (the variable x), it has some parent, and it can be used elsewhere in the code.
Since \code{foo} is a method declaration, the declaration property of the symbol does not make sense.
In this case, it just points to itself.
This way, features like GoToDefinition will just jump to the same symbol, which is the expected behavior.

The declaration of \code{x} in the second line will have many null values within the symbol information.
While the parent is \code{foo}, it can not have any children.
Since it is a variable definition, it still can have usages though.

The final usage of \code{x} in the last line (which we also consider a symbol), does not even have usages, since it is a usage itself.
Thus many properties are null for that last symbol.\\

Unused properties are set to \code{null}.
This causes the risk of \code{NullPointerExceptions}, but should save a lot of memory compared to empty lists or dictionaries.\\

\subsubsection{Symbol Table Creation}
The symbol table generator accepts a precompiled Dafny program in the constructor.
The generator offers a public method \code{GenerateSymbolTable}.
It will first of all create a virtual root symbol.
Any other symbols will be attached to the root node as descendants.
The root node is also the final return value.\\

All modules (similar to \CsharpWithSpace or C++ namespaces) will be extracted out of the Dafny program using functionality provided by Dafny.
The modules will be sorted by depth, so that top level modules will be treated first and nested modules can be attached properly later on.\\

Once the modules are sorted by depth, the algorithm iterates over each of them.
The proper parent symbol will be deduced.
For a top level module, this is just the root symbol.
Otherwise, for nested modules, the parent module will be located.
Once the module is attached to the proper parent, the module will accept the declaration-visitor, which is described below.
Once it has completed, all symbol declarations are registered in the symbol table.
A second iteration is then started, using another visitor, which will ignore declarations but run through all method bodies
and take care of symbol usages.\\
This way, symbols that are declared after the first usage can be found as well.\\

\textbf{Visitors}\\
As already mentioned, the whole symbol table generation is realized using the visitor pattern.
For that, Dafny code had to be adjusted to offer a \code{Accept(Visitor v)} method.
This method will basically just navigate through the internal Dafny symbol representation.
For example, when visiting a method, one would like to register the method itself.
This is done by the expression \code{v.Visit(this)}.
However, a Dafny-\code{method} also contains a Dafny-\code{ensures} statement, which may contain further symbols.
Thus, all statements within the \code{ensures} clause have to be visited.
The \code{Accept}-method will now just forward the call, using \code{foreach (var e in this.EnsureStatements) {e.Accept(v)}}.
The same applies for method parameters and other items like the \code{requires} clause.
Finally, the body of the method is to visit using \code{foreach (var stmt in this.Body) {stmt.Accept(v)}}.
Once everything is done, the scope of the method is left by calling \code{v.Leave(this)}.\\

If you recall the paragraph before the last one, it was said that two runs are performed.
One to capture all declarations, and one to visit all method bodies.
Thus, the visitor is having a boolean property \code{GoesDeep}, which decides if method bodies are visited or not.
The final \code{Accept} method for a method looks as shown in listing \ref{lst:visitoraccept}.
The method is shortened, there are more clauses like for example the \code{requires} clause.


\begin{lstlisting}[language=csharp, caption={Accepting a Visitor}, captionpos=b, label={lst:visitoraccept}]
public override void Accept(Visitor v)
{
  v.Visit(this);
  if (v.GoesDeep)
  {
    foreach (var ens in this.Ens)
    {
      ens.Accept(v);
    }
    foreach (var stmt in this.Body)
    {
      stmt.Accept(v);
    }
  }
  v.Leave(this);
}
\end{lstlisting}

Note that the method is marked with the override keyword.
This is, since every AST-Element is either a statement, a definition or a declaration, among others.
A virtual \code{Accept} method was implemented for these top level classes, which uses a default implementation.
In case a specific AST element got forgotten by us, it will just use the default implementation, which is shown in listing \ref{lst:defaultAccept}.

\begin{lstlisting}[language=csharp, caption={Default Accept}, captionpos=b, label={lst:defaultaccept}]
    public virtual void Accept(Visitor v)
    {
      v.Visit(this);
      v.Leave(this);
    }
\end{lstlisting}

On the other hand of the acceptor, there is the actual visitor.
The visitor has to implement \code{Visit} methods for each of the AST elements
that it is supposed to visit, for example the class \code{Method} from the preceding example.\\

The visitor itself will build up the symbol table.
For that, it stores the current scope in a property.
At the beginning this is the module the iteration was started with.
When visiting a method, the current scope is always some kind of class that was visited before.

The visitor will create a symbol for every element it is visiting.
To do so, all the properties we have seen earlier need to be filled.
The property \code{parent} can just be set with the scope the visitor has stored.
Since the method itself will have its own body, the new scope will then be set to the method-symbol, which is just being created.
All symbols that will be visited afterwards - which is anything inside the method - are then attached to the method.
Once the method is done, \code{Leave()} is called, which will reset the scope to the parent scope for the next item to be visited.\\

Let's continue the example of visiting a \code{method}.
This is a declaration, and thus will be treated by the first visitor, which will register all declarations outside method bodies.
The \code{Visit}-method is shown in listing \ref{lst:visitorvisit1}.
Take note how the symbol is created: All required information is taken from the AST element \code{Method o} that is visited.
This includes the name, the position, and so on.\\

\begin{lstlisting}[language=csharp, caption={Visiting a Method, First Visitor}, captionpos=b, label={lst:visitorvisit1}]
public override void Visit(Method o)
{
    var symbol = CreateSymbol(
        name: o.Name,
        kind: Kind.Method,

        positionAsToken: o.tok,
        bodyStartPosAsToken: o.BodyStartTok,
        bodyEndPosAsToken: o.BodyEndTok,

        isDeclaration: true,
        declarationSymbol: null,
        addUsageAtDeclaration: false,

        canHaveChildren: true,
        canBeUsed: true
    );
    SetScope(symbol);
}
\end{lstlisting}

The \code{CreateSymbol} method will set all properties accordingly.
That means, a symbol that can have children will be initialized with a list for children,
while a symbol that cannot have children will just have a null entry there.
Note that the end of the method, the scope is set to the just created symbol for future visitations.\\

The second visitor, which is responsible for method bodies and symbol usages,
will also visit declarations.
The visitor has actually no choice to skip them, since the \code{Accept}-method decide what is visited in which order.
However, the second visitor no longer creates a symbol for them.
Instead, the already created symbol is located and set as the environmental scope.
The \code{Visit}-method thus gets reduced to listing \ref{lst:visitor2method}

\begin{lstlisting}[language=csharp, caption={Visiting a Method, Second Visitor}, captionpos=b, label={lst:visitor2method}]
public override void Visit(Method o)
{
    var preDeclaredSymbol = FindDeclaration(o.Name, SurroundingScope, Kind.Method);
    SetScope(preDeclaredSymbol);
}
\end{lstlisting}

To find that pre-declared symbol, the symbol table navigator is invoked.
It will just iterate from parent to parent and returns the first symbol, that is a declaration and matches the name.
Challenges occurred when a symbol is defined in global scope or in a inherited base class.
Both difficulties were resolved by adding separate checks for them.
This is completely done by the \code{Navigator} component and not part of the visitor.

The second visitor will now also visit method bodies, since the \code{GoesDeep} property is set to true.
The \code{Accept} method as seen in listing \ref{lst:visitoraccept} is no longer stopping, once the body is treated.
Within the body, local variables exist.
Despite local variables being declarations, they were not handled by the first visitor, which is actually responsible for declarations.
However, this is fine, since local variables are not accessible before they were not declared.
Furthermore, symbol \textit{usages} such as method calls or variable usages are now encountered.
The visitor will create proper symbols for these.
Since these are symbol usages, it is not sufficient to just create a symbol and attach it to the parent scope.
The following additional tasks have to be accomplished:
\begin{itemize}
    \item Where is the symbol declared?
    \item Add a usage to the symbol's declaration
\end{itemize}

To find the declaration, the symbol table navigator is called again just as before.
Once the declaration is known, it is trivial to set the according properties.

\subsubsection{Symbol Table Navigator}
To operate on the (partially) constructed symbol table, a separate component to navigate was created.
It has basically two procedures.
Remember that the data structure of the symbol table is basically a double linked tree.

\begin{itemize}
\item TopDown: Starting from a node, the navigator dives downwards and searches a specific symbol.
\item BottomUp: Starting from a node, the navigator climbs upwards the tree and searches a specific symbol.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{tmpPlaceHolderTodo}
    \caption{TopDown (left) and ButtomUp (right) Visualized}
    \label{fig:impl_symboltablenav}
\end{figure}

Both options are implemented so that they can return a single, first match, or all symbols that match a criterion.
To illustrate this, two examples are shown in figure \ref{fig:impl_symboltablenav}.
With this type of tree inspection, the runtime is reduced, as it is no longer necessary to visit every symbol.

For the special case that the symbol table tree for a Dafny program was built very flat
(a Dafny program, which only uses the default scope with a main method)
the worst case runtime is still $O(n)$ as you can see in figure \ref{fig:impl_symboltablenav_o_of_n}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{tmpPlaceHolderTodo}
    \caption{Dafny Code (left) Which Generates a Flat Symbol Table (right)}
    \label{fig:impl_symboltablenav_o_of_n}
\end{figure}

The navigator overcomes the following challenges.


\textbf{Where is the definition of a symbol}\\
This challenge uses the bottom-up procedure.
It is started from whatever scope the visitor is working on.
In every scope, the navigator will iterate over all symbols and search one, that is a declaration and matches in name and kind.
For example, if we start inside a method, every symbol already visited in that method will be checked.
If no matching declaration was found, the navigator will move to the parent of the method, which must be a class.
Then, all symbols within that class are searched.
Now, the navigator may find a class method that actually matches the search criteria.
Since all declarations were registered beforehand, the process works even if the symbol is declared after the usage, unless it is a local variable, where it must be declared anyway before usage.\\

If the symbol cannot be found, the algorithm will search the default scope at the end as a last option to locate the symbol.
Since the symbol tree is moved upwards, the process takes $O(logn)$ time.
It is executed for every occurring symbol, thus the building of the symbol table takes $O(nlogn)$ time, while n denoted the amount of occurring symbols.\\

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{implementation/findDeclaration.png}
    \caption{Finding a Declaration using the Navigator}
    \label{fig:findDecl}
\end{figure}

\textbf{What symbol is at the current cursor position?}\\
For this task, top-down navigation is used.
Starting from the root symbol, for each child it is checked if it wraps the position.
If not, the symbol is ignored.
But if so, iteration is recursively called on that child.
Reagarding image \ref{fig:topdwon}, imagine we hand the blue line as the cursor position.
The algorith will then decide, that the cursor position is within module M.
Afterwards, it will check all children of \code{M}.
It will find out, that class \code{Z} is not surfacing the cursor position, and move to the next one.
When checking on class \code{C}, wrapping is successfull, thus the next iteration will be done within \code{C}.
Finally, variable c will be returned as the best match.
Default namespaces and default classes had to be treated separately for this case.
Since the tree is moved along a single branch, the runtime for this process is $O(logn)$.\\

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{implementation/topDownPaintFTW.png}
    \caption{Top Down Navigation}
    \label{fig:findDecl}
\end{figure}


\textbf{What AutoCompletion suggestions are indicated?}\\
To build up autocompletion suggestions, all declarations available at a certain locations must be figured.
First of all, the previous \code{TopDown} algorithm is used to find the current location.
Then, all declarations in the current scope are requested, by using \code{BottomUp} again and requesting everything that is a declaration.
This algorithm is diving once into the tree, and going once backup, thus requiring $O(logn)$ time.\\

The navigator offers further methods to visit the whole tree if that is desired by the caller.
The method \code{TopDownAll} will visit all branches, not just the one wrapping a certain location.
Consequently, \code{TopDownAll} requires $O(n)$ runtime and should not be used if possible.
We took advantage of that method to print a complete symbol tree during debugging.



\subsubsection{Symbol Table Manager}
The manager is a rather simple component and can be used as an access point to perform operations on the symbol table.
It is constructed with a root symbol of a fully generated symbol table and contains a navigator.
It then offers methods such as \code{ISymbol GetSymbolAtPosition(Uri file, int line, int character)}.
That method will use the navigator to provide the user with the desired result.
Access to the rather complex navigator is encapsulated this way.

\subsubsection{Symbol Table Utilities}
If a symbol wraps a certain position was first of all a member method of \code{ISymbolInformation}.
However, the class \code{SymbolInformation} got very long this way and testing against the interface was hard.
Thus we decided to extract this very important logic to a dedicated component, which we could test without any effort.
The utilities class offers three distinct types of \code{DoesWrap}-methods.
\begin{itemize}
    \item Is a position wrapped by the entire range of a symbol?
    \item Is a position wrapped just by the body of a symbol?
    \item Is a position wrapped just by the identifier of a symbol?
\end{itemize}
This differentiation was necessary, since for GoToDefinition, only the identifier range matters.
But for AutoCompletion, the body in which the cursor is matters.
Lastly, clauses like \code{ensures} are inbetween those two.
Figure \ref{fig:wraps} shows the distinction between the three methods.

\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{implementation/wraps.png}
    \caption{Top Down Navigation}
    \label{fig:findDecl}
\end{figure}

\begin{itemize}
    \item Green: wrapped by the identifier range
    \item Yellow: wrapped by the body range
    \item Red: wrapped by the entire symbol range
\end{itemize}




\subsection{Features}
\label{section:imp:features}
As it was stated in the previous sections, many features just query the symbol table and assemble the information to a proper result format.
This is especially the case for Rename, GoToDefinition and HoverInformation.
An example was given while explaining the \code{Core}-package of the server implementation.
These features are thus not described in detail any further, since they are nearly trivial.
However, other features, especially AutoCompletion, CodeLens and the ones not depending on the symbol table involve a bit more complexity.
In this chapter, these special cases are described.

\subsubsection{AutoCompletion}
\label{section:implementation:core:completion}
The automatic code completion is an essential feature of every IDE and is a great help for the developer to write code efficiently.
Making good suggestions to the user is a complex matter. \\

Through the new symbol table, it is easy for us to find symbols in the current scope.
With the help of the "Symbol Table Navigator"
it is also possible to efficiently filter the proposals by conditions,
which can be transferred as predicates. \\

The main difficulty and thus the logical complexity of the AutoCompletion
is therefore no longer the actual collection of symbol suggestions,
but the evaluation of what kind of suggestions the user wants in the current context
and extracting a symbol as entry point for the symbol table navigator component. \\

For our AutoCompletion, we support three fundamentally different types of user desire.
To find out the user's desire, the following approach is taken.
First, the cursor position is used to determine the current code position in the Dafny source file.
Then, it is checked if there is a dot or "\code{new }" in front of the cursor position.
Depending on whether one of the two triggers was found,
a decision is made between the three user desires, as shown in figure \ref{fig:get_users_desire}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{tmpPlaceHolderTodo}
    \caption{Evaluating Users Desire - PAP/Ablaufsdiagramm/Flussdiagramm}
    \label{fig:get_users_desire}
\end{figure}

\textbf{Proposals for the Object Instance}\\
If a dot was found at the position of the cursor, the word before the dot is also extracted from the code line.
First of all, the navigator has to find the enclosing scope at the cursor.
For that, it is important to use the wrapping method, that checks if the cursor is within the body of a symbol, not just within the symbol's identifier.
A proper method was implemented which does that.
Afterwards, the related class belonging to the symbol before the dot is searched.
During the search, the navigator starts in the scope at the cursor, and then moves up one level until a suitable symbol is found.
For example, if the user is typing in the method \code{myMethod}, the symbol for \code{myMethod} is returned. \\

If a matching symbol is found, for example a class named \code{myClass}, all methods and fields defined inside \code{myClass}
can be extracted using the symbols properties.
These are now returned as AutoCompletion suggestions. \\

For clarity, the described process is visualized in the following
Dafny code example \intnote{xxx in figure xx} as a sequence diagram.

\begin{lstlisting}[language=dafny, caption={tmptodo.dfy}, captionpos=b, label={lst:tmptodo}]
class myClass {
   var ABC: int;
   constructor () { }
   method myMethod() { /* do something */ }
}
method Main() {
   var abc := new ClassC();
   abc.
}
\end{lstlisting}

todo snipped in IDE screenshotten, cleich auch die resultate listen als screenshot rechts davon

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{tmpPlaceHolderTodo}
    \caption{Sequence Diagram for Object Instances}
    \label{fig:object_completion_diagram}
\end{figure}

\textbf{Class Suggestions}\\
If it is assumed that the user only wants classes proposed, the following approach is followed.

As with the proposals for an object instance,
the completion provider first looks for an access symbol at the cursor position.
Then iteration is performed from the inner scope
to the outermost scope and all symbols found are returned as completion suggestions.
The list is filtered already during iteration by a passed predicate for class symbols only.

 \intnote{todo habe ich jeweils prÃ¤dicate oder delegate geschrieben fÃ¼r die filterung? auch beim result iwo) }
\intnote{ja, passt. ich hab prÃ¤dikat geschrieben dann gibts keine missverstÃ¤nidsse ala "also string genommen ist ein delegate mimi und eig wÃ¤re es eine instanz des edelegates mimi"}
 \intnote{todo wird irgend wo beim visitor manager dingens beschrieben,
 dass zu oberst dann nochmals runter ins default package und in die default klasse gegeagen wird um die "nicht benannten"
 symbole / default scope zu holen? ja, check.}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{tmpPlaceHolderTodo}
    \caption{Sequence Diagram for Class Suggestions}
    \label{fig:new_completion_diagram}
\end{figure}

\textbf{All Available Symbols as Default}\\
If it is assumed that the user would like to have all symbols proposed in the current context,
the procedure is basically the same as before.
The only difference is that no filter is passed to the symbol navigator.
Therefore, all types of symbols are suggested.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{tmpPlaceHolderTodo}
    \caption{Sequence Diagram for all Symbols in Scope}
    \label{fig:default_completion_diagram}
\end{figure}

\code{todo fÃ¼r alle implementationen: Ablauf. Diagramme wie in der SA sind nÃ¼tzlich. das mag "name einsetzen" xD bestimmt. \\
PAP oder flussdiagramm zeichnen fÃ¼r die fall untrscheidungen\\
das vom papier digitalisieren todo\\}

\textbf{Insertion of Parameter Placeholders}\\
Just like in other programming languages, Dafny invokes methods and constructors by round brackets.
It was our goal to automatically propose those brackets.
This goal could easily be achieved.
Whenever a constructor or method is chosen as an AutoCompletion suggestion,
an opening and closing bracket is added to the text to be inserted. \\

From certain IDE's such as XCode,
you are used to seeing placeholders for the parameters and their types in AutoCompletion
when you select a method from the suggestions \cite{sa}.
That is why we wanted to implement such a convenient feature for our AutoCompletion as well.
Unfortunately we had to realize that this feature is not yet supported natively by the VS Code API \cite{vscodeAPI}.
Neither does the LSP support a standard for the explosive insertion of parameters \cite{lspspec}. \\

That there is no simple way to implement this feature does not mean that it cannot be done.
But the effort for the implementation in VS Code would be exceptionally high.
Therefore we have decided not to support this feature.
However, the symbol table stores a parameter list for every method, constructor, and function.
Thus, the symbol table is ready to support the functionality.
The complete idea how the feature could be implemented is described below. \\

As with CodeLens, you could send additional data to the client
for the AutoCompletion objects - namely the parameters and their types for methods.
Whenever a completion is inserted, a callback function can be called within the client.
This function could then additionally insert the parameters as text in the code and register
event listeners on keyboard keys like \textit{TAB}.
Using \textit{TextEdits}, the registered function would then jump to the next placeholder parameter
each time \textit{TAB} is pressed and mark it, so that the user can easily replace it with his own code. \\

Also, just because VS Code does not yet offer an API to perform such \textit{TAB} jumps between parameters,
does not mean that other IDE's, for which Dafny support will be offered later,
do not offer such a function.
In the future, VS Code might even add such a function. \\

\textbf{Getting Information About Method Parameters} \\
Usability test has shown that text information about which method
receives which parameters would still be very helpful for users.
The information provided by the symbol table could be used for that.

When constructing the completion elements,
the field \code{CompletionItem} can contain additional details.
Those details could hold the parameter list.
This way, the user could be informed about them.\\


\subsubsection{CodeLens}
\label{section:implementation:features:codelens}
The CodeLens functionality is divided into two primary tasks.

First, it is shown how often the method or class has already been used.

Second, the user can click on the text and a popup window displays all symbol usages.
This allows the developer to efficiently jump between different places within a workspace.\\

\textbf{Number of References} \\
To get the reference count, no big effort is necessary thanks to the new symbol table.
It contains a list of \code{Usages}, which can easily be counted.
This way, it can also expose dead code, which has never been used as seen in \ref{fig:codelens_show_ref_number}. \\

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{tmpPlaceHolderTodo}
    \caption{CodeLens shows Number of Counted Referances}
    \label{fig:codelens_show_ref_number}
\end{figure}

\textbf{Popup Windows with Code Snippets} \\
The popup that opens when you click on the grey text
with the reference counter is a client feature.
It is offered by VS Code \cite{vscodeAPI}.
Unfortunately, this is something that cannot be extracted completely to the server.
The logic required within the client is trivial, though.
Only the function \code{VSCodeCommandStrings.ShowReferences},
offered by VS Code, is called \cite{vscodeAPI}.
The popup display is shown in figure \ref{fig:codelens_show_popup}. \\

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{tmpPlaceHolderTodo}
    \caption{CodeLens shows Popup with Code Snippets}
    \label{fig:codelens_show_popup}
\end{figure}

The preparation of the data is already done in the language server.
For each symbol declaration, the CodeLens object is enriched with further information.
The client just has to display them.
This is shown in listing \ref{lst:codelens-prep}.

\begin{lstlisting}[language=csharp, caption={LSP Handler Implementation}, captionpos=b, label={lst:codelens-prep}]
var args = new
{
    Uri = _uri,
    Position = position,  // where to show the CodeLens popup
    Locations = locations // what should be displayed inside the popup
};
Command command = new Command
{
    Title = msgTitle,
    Name = "dafny.showReferences",
    Arguments = new JArray(JsonConvert.SerializeObject(args))
};
return new CodeLens
{
    Data = _uri,
    Range = range,
    Command = command
};
\end{lstlisting}
 \intnote{todo merke grad dass showreferences ein Ã¼bersehenes magic string ist... in ressourcen auslagern? todo}

To each CodeLens element, a \code{Command} object is also appended.
The command's name is the function called at the client, when the grey text is clicked.\\

In addition, the \code{Command} is given the positions it should display inside the popup.  \\

If the function \code{dafny.showReferences} is called in the client,
the method \code{VSCodeCommandStrings.ShowReferences} from the VS Code API is called
and the arguments prepared in server are passed through. \\

Because the whole logic for CodeLens is in the server,
integration tests and unit tests were written on the server side for this feature.\\

\textbf{Support for File Includation} \\
CodeLens works very well over multiple files.
But only if other files are included.
In case the currently opened file is included by another file,
CodeLens does not know that it gets used by a third Dafny program. \\

This problem should solve itself once a global symbol table for the complete workspace has been implemented,
instead of a single table per file.
Symbols will then be aware of usages across the complete workspace.
More information about the global symbol table is described in section xxx.

 \intnote{todo XXX mit Kapitelreferenz auf updatebare globale symbol tabelle manager dingens tun. seh grad ned welche skapitel es ist. haben wir das schon geschrieben? todo -- is noch nicht... wÃ¤re was fÃ¼r results}

\subsubsection{Compilation}
Every time a file gets updated, the whole Dafny backend is triggered and the results are stored in a \code{FileRepository}.
This includes the precompiled \code{dafnyProgram}, which is then available for further reuse.
The compilation provider will take advantage of that and use the precompiled item, and just forward it to the Dafny compiler engine.
Prior to the compilation, custom compilation arguments are installed, if the user provided any.
The process is fully integrated into the Dafny backend.
The compiler invocation can be seen in listing \ref{lst:dafnycompiler}.\\

\begin{lstlisting}[language=csharp, caption={Calling the Dafny Compiler}, captionpos=b, label={lst:dafnycompiler}]
DafnyDriver.CompileDafnyProgram(dafnyProgarm, filePath, otherFiles, true, textwriter);
\end{lstlisting}

The provider will check if any errors occurred during the process and return the outcome within a wrapper class.
The handler can then read the outcome and send a proper message to the user.

\subsubsection{CounterExample}
This feature bases on the model file, which is generated during verification.
The model file is a key-value store generated by Boogie.
It contains several 'states'.
Each state tracks the content of variables during different stages of the proof.
Of interest is primarily the \textit{initial} state, since this one contains the information how variables
need to be set initially to achieve a CounterExample.\\

The CounterExample provider reads the model file and uses the Boogie backend to convert it into a useful format, which is called \code{ILanguageSpecificModel}.
Afterwards, it extracts the initial state from the model.
Out of the remaining state, all key-value-pairs are extracted, filtered, assembled and returned.
Many values are internal Boogie references and cannot be resolved.
These just look like \code{T@U!val!12}.
Such values are replaced with the text \code{[Object Reference]}.
Values providing no information at all are completely removed from the CounterExample.
The component will also transform information into a more human readable format, e.g. \code{((- 12)) $\rightarrow$ -12}.\\




%%%%%%%%%%%%%%%%%%%%TOMS WORK IN PROGRAESS HIER WEIT_ER MARKER/&&&&%%%%%%%%%"*Ã§TQFGAWZHAZAZE%HRAZEHAEZ%RAEZ%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Mono Support for macOS and Linux}
\label{section:implementation:mono}
One of the core objectives was to provide support for multiple platforms.
This means that in addition to Windows, macOS and Linux should be also supported. \\

In the preceding thesis, we had to switch from .NET Core to .NET Framework \cite{sa}.
The reason for this was that although OmniSharp was compatible with .NET Core,
the Dafny backend was not \cite{sa}.\\

.NET Core has native support for Linux and macOS.
With .NET Framework, however, a Windows executable is generated upon compilation.
Therefore, one has to rely on Mono for Unix based operating systems.
Mono allows to execute \code{.exe} files on said systems \cite{mono}. \\

Unfortunately, in the course of our thesis we discovered that the language server could not be started correctly with Mono.
The problem already occurred when trying to start the OmniSharp language server component. \\

We took several measures to get even more specific details about the problem, after we found the specific point of failure.

\begin{itemize}
    \item We have built a new try-catch around it - just in case. But the catch is not called because no exception is thrown.
    \item Because we use .NET Framework and not .NET Core, we could not debug step by step on macOS.
    \item Debugging the log output was not helpful since no log output was produced at all.
    \item We tried to start a very simple language server - without the Dafny project - and could not execute it correctly with \code{msbuild}.
    \item We tried different mono versions: 6.6.0.166 (2019-08) and 6.8.0.105 (2020-02).
    \item We tested on macOS as well on Linux.
\end{itemize}

This made troubleshooting very difficult for us.
Unfortunately, we could not find out why the OmniSharp server start-up does not work correctly with mono.
The OmniSharp community could not help us either \cite{mono-slack}.\\

While researching GitHub issues, it turned out that there are fundamental problems with Linux and Mac,
as OmniSharp developers primarily develop and test on Windows \cite{mono-git}.

In consultation with our supervisor, we then put the problem on hold after a certain amount of time had been used.
Later on, Fabian Hauser noticed that instead of \code{msbuild} we would have to switch to \code{dotnet build}.

Since \code{msbuild} is required for our Sonar scan and the limited time left,
we decided not to take up the problem again in the last weeks of the project.
However, this would certainly be a good approach to solve the problem.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Testing}

This section provides a general overview of the testing.
It is split into unit and integration tests.
To read how to write tests or why we worked with interfaces for dependency injection, refer to the development document.

\subsubsection{Unit Tests}
Since all our core components are progarammed against interfaces, testing them is not that hard.
One can simply create fake, mock or stub, implementing the interface, and use it for testing purposes.\\

\textbf{Symbol Table Generation}\\
To test the symbol table generation, dedicated Dafny files were written.
The tests first call the \code{DafnaTranslationUnit} to create a dafnyProgram.
The dafnyProgram is then handed to the \code{SymbolTableGenerator}.
The output is - once more - converted into a string representation.
This outcome is then compared a against an expectation file.\\

Technically, since the \code{TranslationUnit} is inovked as well, the test is not completely isolated.
One would have to serialize the dafnyProgram, and use that one as a test input.
However, to be able to quickly adjust the testfile, this was not done.\\

Another flaw of this test is, that the whole symbol table is tested at once.
There is not a single test that checks if symbol X gets used 5 times - and checks only that.
The string representation contains information about every symbol of the whole code at once, and the whole code is tested.
While this is not best practice, it allowed us for a much more efficient testing.
Even if a test fails, the string representation displays exactly why it failed, so there is not a big downside to this.\\

An example expectation file of this test is shown below:

\begin{verbatim}
[L0:C0] "_module" | P : [L0]_programRootNode | D : self | C : 2 | U : 0
[L1:C7] "MyClass" | P : [L0]_module | D : self | C : 4 | U : 0
[L3:C9] "field" | P : [L1]MyClass | D : self | C :  | U : 2
[L5:C13] "add" | P : [L1]MyClass | D : self | C : 3 | U : 1
[L5:C17] "i" | P : [L5]add | D : self | C :  | U : 1
[L5:C25] "j" | P : [L5]add | D : self | C :  | U : 1
[L5:C42] "r" | P : [L5]add | D : self | C :  | U : 2
[L6:C8] "r" | P : [L5]add | D : [L5]r | C :  | U : 
[L6:C13] "i" | P : [L5]add | D : [L5]i | C :  | U : 
[L6:C17] "j" | P : [L5]add | D : [L5]j | C :  | U : 
[L7:C15] "r" | P : [L5]add | D : [L5]r | C :  | U : 
[L10:C12] "aMethod" | P : [L1]MyClass | D : self | C : 1 | U : 0
[L10:C31] "this" | P : [L10]aMethod | D : [L1]MyClass | C :  | U : 
[L11:C13] "aLocalVar" | P : [L10]aMethod | D : self | C :  | U : 2
[L12:C9] "field" | P : [L10]aMethod | D : [L3]field | C :  | U : 
[L12:C18] "aLocalVar" | P : [L10]aMethod | D : [L11]aLocalVar | C :  | U : 
[L13:C9] "aLocalVar" | P : [L10]aMethod | D : [L11]aLocalVar | C :  | U : 
[L13:C22] "add" | P : [L10]aMethod | D : [L5]add | C :  | U : 
[L13:C26] "field" | P : [L10]aMethod | D : [L3]field | C :  | U : 
[L16:C5] "_ctor" | P : [L1]MyClass | D : self | C : 0 | U : 0
[L0:C0] "_default" | P : [L0]_module | D : self | C : 0 | U : 0
\end{verbatim}

The reader takes note that the test expectation is simplified.
It is not exactly tested, if symbol X is used by symbol Y.
Instead, just some counts are checked.
However, by testing if the parent is correct, and by testing the children count, we can be confident that the parent-child relationship is correct.
The same applies for the declaration-usage relation.
You further note, that there is no information given about base clases, parameter lists or such.
But items like these are indirectly tested.
If the base-class would not not be attached properly, a symbols declaration would not be found, which could be seen in the string representation.

\textbf{Symbol Table Navigation}\\
To test the navigator and manager component, a fake symbol class was created.
It allows to define the symbol position within the constructor.
Afterwards, symbols can be attached to each other at will.
This way, the top-down and bottom-up algorithms could be tested.
An example is shown in listing \ref{lst:botuptest}.

\begin{lstlisting}[language=csharp, caption={Navigator Unit Test}, captionpos=b, label={lst:botuptest}]
public void BottomUpFirstChild()
{
    SymbolInformationFake rootEntry = new SymbolInformationFake(1, 0, 1, 0, 5, 0, defaultFile, "Parent");
    SymbolInformationFake mySymbol = new SymbolInformationFake(2, 0, 2, 0, 5, 0, defaultFile, "Child");
    rootEntry.AddChild(mySymbol);
    mySymbol.SetParent(rootEntry);
    Predicate<ISymbolInformation> filter = (s => s.Name.Equals("Child"));
    var symbol = nav.BottomUpFirst(mySymbol, filter);
    Assert.AreEqual(mySymbol, symbol);
}
\end{lstlisting}

\textbf{Core Provider}\\
To efficiently test the core providers, a \code{FakeSymbolTableManager} was created.
It wraps a symbol table, in which a few fake symobls are attached to each other.
Within the constructor of the fake-manager, it is told which symbol the manager will statically return.
This way, the navigator component is not invoked.\\

This fake manager is used to test features like Rename, GoToDefinition or HoverInformation.
It could just be injected to the providers, since the required interface \code{ISymbolTableManager} is implemented.
By this construct, the correct assembly or Renamings or HoverInformation could be tested.
An example is shown in listing \ref{lst:renameUnit}

\begin{lstlisting}[language=csharp, caption={Core Provider Unit Test}, captionpos=b, label={lst:renameUnit}]
public void ReservedWord()
{
    ISymbolTableManager manager = new FakeSymbolManager(returnsDeclaration: false, returnsNull: false);
    var provider = new RenameProvider(manager);
    var result = provider.GetRenameChanges("method", new Uri("file:///N:/u/l.l"), 2, 22);
    Assert.IsTrue(provider.Outcome.Error, "error expected in rename-outcome");
    Assert.AreEqual("method" + DafnyLanguageServer.Resources.LoggingMessages.rename_reserved_word, provider.Outcome.Msg);
}
\end{lstlisting}

\textbf{Core Provider not depending on the Symbol Table}\\
The features Compile and CounterExample are the only ones not depending on the symbol table.
These were already tested in a similiar matter in the prototype.\\

To test CounterExamples, a custom \code{model.bvd} file can be injected into the provider.
This way, predefined model files are analyzed instead of the model from the live Dafny code.\\

To test compilation, a \code{.dfy} file is defined in the test method.
The test will again call the translation unit, to create \code{TranslationResults}.
Again, this is not optimal but practical.
Out of the translation results, a file repoistory is created, which is then handed to provider.


%%%%%%%%%%%%%INTEGRATIONM TEST

\subsubsection{Integration Tests}

Unlike in the preceding semester thesis, integration tests were implemented using Omnisharp's language server client \cite{omnisharpClient}.
Each test starts a language server and a language client, then they connect to each other.
Now, the client can send supported requests, such as the request for CounterExamples.
The result can be directly parsed into our \code{CounterExampleResults} data structure and be compared to the expectation.
Thus, tests can be written easily and are very meaningful and highly relevant.

\textbf{Dafny Test Files}\\
Integration Tests usually run directly based on \code{.dfy} source files.
Those test files need to be referenced from within the test.
To keep the references organized, a dedicated project \code{TestCommons} was created.
Each test project has access to these common items.
Every test file is provided as a static variable and can thus be easily referenced.

\begin{lstlisting}[language=csharp, caption={Test File Reference}, captionpos=b, label={lst:semiExpectedCodeThing}]
public static readonly string cp_semiexpected = CreateTestfilePath("compile/semi_expected_error.dfy");
\end{lstlisting}
The class providing these references will also check, if the test file actually exists, so that \code{FileNotFoundErrors} can be detected early.

\textbf{String Converters}\\
Many tests return results in complex data structures, such as \code{CounterExampleResults}.
Comparing these against an expectation is not suitable, since many fields and lists have to be compared against each other.\\

To be able to easily compare the results against an expectation,
a converter was written to translate the complex data structure into a simple list of strings.
For example, each \code{CounterExample} will be converted into a unique string, containing all information about the \code{CounterExample}.
All \code{CounterExamples} together are assembled within a list of strings.
This way, they can be easily compared against each other.
One could also overwrite \code{Equals(object other)}, but with the string representation, the developer has a direct visual feedback what caused the mismatch.\\

Since not only \code{CounterExamples}, but also other data structures such as \code{Diagnostic} were converted into lists of strings,
the converters were held generic as far as possible.
Listing \ref{lst:genericconverter} shows how this was realized.
The method takes a enumerable of type \code{T} as an argument, and a converter which converts type \code{T} into a string.
Each item in the enumerable is then selected in the converted variant.

\begin{lstlisting}[language=csharp, caption={Converting CounterExamples to a List of Strings}, captionpos=b, label={lst:genericconverter}]
private static List<string> GenericToStringList<T>(this IEnumerable<T> source, Func<T, string> converter)
{
    return source?.Select(converter).ToList();
}

public static List<string> ToStringList(this List<CounterExample> source)
{
    return GenericToStringList(source, ToCustomString);
}

public static string ToCustomString(this CounterExample ce)
{
    if (ce == null)
    {
        return null;
    }
    string result = $"L{ce.Line} C{ce.Col}: ";
    result = ce.Variables.Aggregate(result, (current, kvp) => current + $"{kvp.Key} = {kvp.Value}; ");
    return result;
}
\end{lstlisting}

Comparison of the results and the expectation is now very simple.
The expectation can just be written by hand as follows:

\begin{lstlisting}[language=csharp, caption={Expectation}, captionpos=b, label={lst:testexpectation}]
List<string> expecation = new List<string>()
{
    "L3 C19: in1 = 2446; ",
    "L9 C19: in2 = 891; "
};
\end{lstlisting}

This is much more convenient than creating a custom \code{CounterExample}, which could then be used for comparison with an \code{Equals}-method.
By taking advantage of the method \code{CollectionAssert.AreEquivalent(expectation, actual)} from nUnit's test framework,
the two lists can be easily compared against each other \cite{nunitCollectionAssert}.

\textbf{Test Architecture}\\
Since every integration test starts the client and the server at first, as well as disposes them at the end,
this functionality could be well extracted into a separate base class.
This class is called \code{IntegrationTestBase} and just contains two methods, \code{Setup} and \code{Teardown}.
These methods could be directly annotated with the proper nUnit tags,
so that every test will at first setup the client-server infrastructure,
and tear it down after the test has been completed.\\

A second base class exists for each feature.
For testing compilation, this class is named \code{CompileBase} as an example.
It inherits from the \code{IntegrationTestBase} class and provides the member \code{CompilerResults},
as well as two methods \code{RunCompilaton(string file, string[] args)} and \code{VerifyResults(string expectation)}.
The implementation of \code{RunCompilation} is shown in listing \ref{lst:runIntegrationtest}.\\

\begin{lstlisting}[language=csharp, caption={Running a Compilation Integration test}, captionpos=b, label={lst:runIntegrationtest}]
protected void RunCompilation(string testfile, string[] args)
{
    CompilerParams compilerParams = new CompilerParams
    {
        FileToCompile = testfile,
        CompilationArguments = args
    };
    Client.TextDocument.DidOpen(testfile, "dfy");
    compilerResults = Client.SendRequest<CompilerResults>(compileKeyword, compilerParams, CancellationSource.Token).Result;
}
\end{lstlisting}

The test class itself inherits from its feature-specific base class.
The tests itself are very simple.
For example, if we want to test if the compiler reports a missing semicolon, we could create a test class \code{public class SyntaxErrors : CompileBase}.
Note that we inherit from our case-specific base class.
Thus, the methods \code{RunCompilation} and\code{Verify} are at our disposal.
That means, that the test is as simple as follows:

\begin{lstlisting}[language=csharp, caption={Sample Test for Missing Semicolon}, captionpos=b, label={lst:demoTest}]
[Test]
public void FailureSyntaxErrorSemiExpected()
{
    RunCompilation(Files.cp_semiexpected);
    VerifyResults("Semicolon expected in line 7.");
}
\end{lstlisting}


As you can see, the test contains only two lines of code.
The first is stating the test file, the second one the test result expectation.
Tests for other features look quite similar, just the expectation format may be different.
Thus, the integration test architecture could be created in a way so that the creation of tests is extremely simple.
The code is kept very clean and contains no duplicated parts.
Tests can easily be organized into classes \textendash{} considering compilation, this could for example be the separation into logical errors, syntax errors, wrong file types and so on.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth/2]{integrationTestDesign.png}
    \caption{Test Architecture on the Basis of Compilation}
    \label{fig:testArchitecture}
\end{figure}



 
\subsection{Usability Test}
Since we have been developing and using our plugin for many months,
it is sometimes difficult to differentiate the results.

Therefore we have designed a usability test and found a test person to perform this test \cite{interview-remo}.
The test person, Remo Herzog, was chosen because he is programming in an environment based on VS Code
and therefore is well integrated into the corresponding VS Code universe. \\

The goal of this test was primarily to find out if the features
we implemented were implemented as a VS Code Plugin user would expected them to be,
and which features were expected to be different in terms of display and triggering. \\

The general usefulness would also be discussed and feedback for further improvements was collected.
These improvements are discussed in this chapter.

\subsubsection{Code Documentation for Classes and Methods}
If you drive over symbols and the hover information is displayed,
and if the AutoCompletion is listing symbols,
a code documentation is missing in the corresponding info boxes.
It would be desirable to have a code documentation for methods and classes,
which is displayed additionally with the mentioned features. \\

This feature could be realized with the new symbol table. The approach would be the following:

Through the feature CodeLens all declarations of methods and classes are already known.
For each of these symbols the correct position in the Dafny source code could be read out
and with a regular expression found code documentation comments could be read out.
The documentation text, read out by the pattern matching, can then be stored in the corresponding symbol as code documentation.
This information can then be sent to the client via the LSP and displayed,
for example in the case of AutoCompletion or hover information,
as a \code{documentation} element \cite{vscodeAPI}.

\subsubsection{Cleaner Hover Information}
The information which is displayed in a symbol during a hover event was felt to be somewhat confusing.
Sometimes the terms like \code{kind} were not clear.
By using markdown instead of plaintext, HoverInformation could be improved significantly, as shown in figure \ref{fig:hoverNowVsThen}\\

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{tmpPlaceHolderTodo}
    \caption{Hover Before (left) and Cleaner Version (right)}
    \label{fig:hoverNowVsThen}
\end{figure}

\subsubsection{Automatic Triggering of AutoCompletion}
If a dot is typed while typing, AutoCompletion suggestions are automatically expected.
You should not have to press \code{control + space} as trigger.
This issue was anyway pending and was implemented shortly after the usability test.

In addition, the suggested methods lacked to inform about the supported parameters.
With regard to the parameters, this has already been discussed in section  \intnote{Todo}. \\

\subsubsection{Error Message Without Brackets}
Error messages are reporting the code symbol at which the error occurrs.
For example, when the error starts at the body of a method, the error message contains \linebreak
\code{Assertion Violation at [ { ] in line 5.}}.
The square brackets were confusing the testperson.
Thus it was decided to leave them out, and instead show the code token on a new line.
This should be less confusing.
The issue is shown in figure \ref{fig:cleaner_error_msg}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{tmpPlaceHolderTodo}
    \caption{Error Message before (top) and after (bottom)}
    \label{fig:cleaner_error_msg}
\end{figure}


\subsubsection{Compile Improvements}
Some plugins have a small green play icon in the upper right corner of the IDE for compilation,
which can be pressed.
The test person would have wished such a play button  \cite{interview-remo}. \\

It is possible to also add this icon for Dafny. If the button is clicked, a compile and run is triggered.
Similar to the UI elements for the Dafny status bar,
a button can be created by the VS Code API \cite{vscodeAPI}.
It can be assigned an icon and a click action.
Due to the lack of time, the feature could not be implemented anymore, though.\\

When running the Dafny program,
a lot of text messages are displayed,
which distract from the relevant output.

To shorten the message length, full paths could be ommitted and insetad, just file names are shown.
This is illustrated in figuire \ref{fig:long_compile_output}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{tmpPlaceHolderTodo}
    \caption{Output to be Improved}
    \label{fig:long_compile_output}
\end{figure}

\subsection{Continuous Integration (CI)}
Optimizing the CI process is an important part of our thesis.
Since we expect that our language server as well as the Dafny client plugin will be further developed by other developers,
the CI is a primary component of automated quality assurance. \\

This includes that the CI pipeline will fail if certain quality attributes are not met.
These include, in particular, successful completion of automated tests,
static code analysis and formatting control of the TypeScript code. \\

More details on the quality aspects are described in chapter \ref{section:project_management} \nameref{section:project_management}.
This section describes how the planned improvements for the CI process from chapter \ref{section:analysis:CI} were implemented.

\subsubsection{SonarQube}
According to our research, a major problem was that the scanner for SonarQube can only analyze one language at a time \cite{sonar-supports-only-one-language}.
This means, that the TypeScript code in the client and the \CsharpWithSpace code in the server cannot be analyzed simultaneously.
Furthermore, in the pre-existing Dafny project, single Java files appear, too.
This led to further conflicts in the Sonar analysis \cite{sa}.\\

As a simple solution, we decided to separate the client (VSCode plugin) and server (Dafny Language Server) into two separate git repositories.
This not only simplifies the CI process but also ensures a generally better and clearer separation. \\

As a result, the client could still be easily analyzed with the previous Sonar scanner.
Regarding the server, a special Sonar scanner for MSBuild had to be installed, which publishes the analysis in a dedicated SonarCloud project \cite{dev}.
The available statistics are very helpful for code reviews.\\

As a little extra, not only our Dafny language server part is analyzed by Sonar,
but the whole Dafny project.
From the bugs, vulnerabilities, code duplications and code smells revealed
by this analysis, the whole GitHub team working on the Dafny project can benefit. \\

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth-2cm]{sonarexamaple.png}
    \caption{Example of a Useful Sonar Finding}
    \label{fig:sonarexample}
\end{figure}

Unfortunately, the code coverage by tests is not analyzed.
Searching for an alternative, \textit{OpenCover} was found as a very common tool for code coverage analysis in \Csharp.
Unfortunately, it only runs under Windows  \cite{opencover}.
The CI server bases on Linux, though.
During our research we came across \textit{monocov} \cite{monocov}.
This tool would run under Linux and analyze .NET Framework projects.
Unfortunately, this project was archived and has not been maintained for almost 10 years \cite{monocov}.

Since we would not gain much value with sonar code coverage, we decided not to pursue this approach any further.
The coverage information is provided by the ReSharper extension \textit{dotCover} \cite{dotcover} to the developers.

\subsubsection{Client End-to-End Tests}
The end-to-end tests base on a lot of dependencies, such as a headless instance of Visual Studio Code.
In consultation with our supervisors, we have removed these tests from the client project and replaced them with own specially written integration tests on the server side.
This can be justified with the client only containing a minimal amount of logic that is required for the visual representation.
Any other logic was moved to the server.

\subsubsection{Static Program Analysis and Formatting for TypeScript}
During development it became apparent that it would be useful to check the correct formatting
for the TypeScript code from the client in the CI.
Various tools are used locally, which automatically format the syntax correctly when saved.
These tools are described in the developer documentation \cite{dev}.
However, if someone does not install these tools,
and the code is not formatted according to the definition,
the CI pipeline will fail. \\

Prettier was selected for this function.
Alternatively, ESLint would have been an option \cite{eslint}.
This would also have automatically integrated a static code analysis in the CI.
However, we decided to use a combination of SonarLint and Prettier,
so that the local analysis tool is matched to SonarQube \cite{dev}.

\subsubsection{Docker}
For an easier testability of the CI, we installed Docker locally.
This allowed us to resolve CI issues locally and platform-independently (through the Docker Client) in case of problems.
More details are stated in the developer documentation \cite{dev}.
The documentation found there helps future developers to easily and efficiently test changes to the docker container locally. \\
