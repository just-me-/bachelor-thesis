\section{Einleitung und Übersicht}

\subsection{Ausgangslage}

\subsection{Überblick Lösungen}
\begin{itemize}
    \item WLAN Probe Requests
    \item Computer Vision mit traditionellen und Deep Learning Methoden
    \item Lichtsensoren etc.
\end{itemize}

\subsection{Überblick über Artifical Intelligence (AI)}
Grundsätzlich gilt, dass formal beschriebene abstrakte Probleme, die schwer sind für uns Menschen wie komplexe Berechnungen, einfach durch einen Computer ausführbar sind. Wenn es jedoch mehr um menschliche Intuition geht, wie dies beim Erkennen von Objekten in Bildern, wie auch beim Verstehen von Gesprächen der Fall ist, kann dies schwer formal definiert beschrieben werden und ist somit sehr schwierig auf einen Computer übertragbar \cite{good}. \\
% structured/unstructured data von coursera
% Begriffe mit eigenem Venn Diagramm darstellen

Machine Learning versucht solche Probleme zu lösen, indem sich ein System durch Mustererkennung in Daten eigenes Wissen aneignet. So können z.B. einfache ML Algorithmen zwischen normalen E-Mails und Spam E Mails unterscheiden. \cite{good}\\

Das Problem bei klassischen ML Algorithmen ist, dass die Verarbeitung stark von der Darstellung von sogenannten Features abhängen. Features bezeichnen ein Stück Information (z.B. ein Pixel in einem Bild), dass als Input in ein ML System dient. So kann es z.B. sein, dass die Farbe eines Pixels durch Sonneneinstrahlung oder Dunkelheit stark verändert wird. \cite{good} \\

Eine andere Art von Machine Learning löst dieses Problem, in dem es Representationen von Informationen als andere, einfachere Konzepte darstellt. Diese Herangehensweise nennt man Deep Learning. \cite{good}
% Bild noch beschreiben
% Figure 1.2 (Seite 6 bzw. 21 Chrome) in Buch!! etwas ähnliches einfügen
% hidden layer erklären (Seite 168)
% anderes Bild https://i2.wp.com/semiengineering.com/wp-content/uploads/2018/01/MLvsDL.png?ssl=1, so etwas ähnliches mit einer Person machen

% Jede Stück Information wird als Feature bezeichnet. Verarbeitung ist abhängig davon wie das Feature dargestellt wird.
% representation learning = nicht nur Input/Output Mapping wird gemacht, sondern auch die Repränsetation/Darstellung miteinbezogen. So können die Features durchs System selber festgelegt werden z.B. autoencoder
% ziel bei representation learning: factors of variation (= Einflussfaktoren) zu trennen
% bei einem Auto wären Postition des Autos, Farbe, Winkel/Helligkeit der Sonneneinstrahlung factors of variation
% Problem: Die Einflussfaktoren verändern evtl. jedes Feature (z.B. jedes Pixel eines Bildes, wenn es Dunkel ist)

% Supervised, unsupervised Learning: supervised learning samples sind mit Labels versehen worden (eine Person hat somit Bilder mit Daten versehen)

% evtl. Deep Learning und CNN Teil zusammennehmen
\subsection{Convolutional Neural Network (CNN)}
Convolutional Neural Networks zählen zu den Deep Feedforward Networks (auch feedforward neural networks, multilayer perceptrons (MLPs) genannt). Feedforward neural networks bestehen typischerweise aus mehreren Funktionen, die aneinander gereiht werden f(x) = f''(f'(f(x))). Während einer Trainingsphase wird die Funktion f(x) so definiert, dass sie eine andere Funktion f*(x) approximiert. f*(x) stellt z.B. ein Mapping eines Featuresvektors auf eine Kategorie (z.B. Mensch) dar (dies nennt man einen Klassifizierer). \cite{good}
