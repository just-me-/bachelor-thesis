\section{Implementation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Client}
a



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Server}


\subsubsection{Server Launch}
As done in common practice, the \code{Main} function is kept very short. All it does is launching the language server, which is already handled by another class.

\begin{lstlisting}[language=csharp, caption={Main Function}, captionpos=b, label={lst:main}]
public static async Task Main(string[] args)
{
    DafnyLanguageServer languageServer = new DafnyLanguageServer(args);
    await languageServer.StartServer();
}
\end{lstlisting}

The launch of the server itself is devided into four stages. First, preparational work is done. This happens already in the constructor of the language server. Preparation includes
\begin{itemize}
    \item Reading and processing config variables
    \item Setting up the logging framework
\end{itemize}
Secondly, the actual server is launched. The logger will directly be injected and all handlers are registred. In the third stage, once the server is running, a message sending service is instanciated to notify the client about the successful server start and, if any, errors occured during startup. Lastly, the console output stream is redirected to keep the langauge server stream clean.

\begin{lstlisting}[language=csharp, caption={Starting the Language Server}, captionpos=b, label={lst:serverstart}]
public async Task StartServer()
{
    log.Debug(Resources.LoggingMessages.server_starting);
    server = await LanguageServer.From(options => \dots  );
    ExecutePostLaunchTasks();
    await RedirectStreamUntilServerExits();
    log.Debug(Resources.LoggingMessages.server_closed);
}
\end{lstlisting}

\subsubsection{Tools}
Within the tools package, a variety of services can be found that do not necessarily directly correspond to Dafny, but are useful within the language server environment.\\

\textbf{Config Initializer}\\
\intnote{kann man hier so subsubsubchapter machen? geht das iwie? sons tienfach so lassen oder?}
This class is called prior to the server launch and initializes a few config settings. The settings are stored within the static class \code{Commons/LanguageServerconfig.cs}. The config initializer will first of all set hard coded default values to avoid any kind of null pointer exceptions. Afterwards, the file \code{Config/LanguageServerConfig.json} is parsed with Newtonsoft's Json.NET library \cite{jsondotnet}. Any available values will be written to the static configuration class. Unkown or illegal values will not be set and errors are added to a error reporter. Finally, the launch arguments are parsed, again overwritting the config settings if applicable or reporting errors otherwise. A simple argument parser was implemented manually. Alternatively, a library could have been used for this task such as \cite{clparser}. The config initalizer is implemented exception safe. This means that it will run to completion and at wrost just provide default values. Errors can later be extracted from the \code{InitializationErrors} property.\\

\textbf{LoggerCreator}\\
This class simply sets up a Serilog \cite{serilog} logger. For this purpose, it will already read from the static config class \code{Commons/LanguageServerconfig.cs} the information what the minimum loglevel is and where to locate the logfile.\\

\textbf{MessageSenderService}\\
This is a simple class accepting a \code{ILanguageServer} in the constructor. Afterwards, it provides methods to send notifications to the client. Simliar to logging, methods for each severity level are available, such as \code{public void SendError(string msg)}.\\

\textbf{ReservedWordsProvider}\\
This is a class reporting simply offering a method returning a set of words, that are not suited for identifiers. This is, for example, 'method', 'class', or 'return'. The class tries to read and parse \code{Config/ReservedDafnyWords.json}, which can be user adjusted in case the Dafny specification changes. If the file cannot be read or has a wrong format, a hard coded default list is used which was taken out from the Dafny Reference Manual \cite{dafnyReferenceManual}.\\

While this component is specifically used solely for the \code{rename}-Feature, it was extracted to be also available at other spots if required for future features.\\

\subsubsection{Handler}
Handlers are passed to the language server and are called whenever the language server receives a corresponding request. Services, such logging or workspace management, can be injected and are thus available for the handler. Omnisharp directly defines interfaces, which have to be used for the handler implementation. For example, the interface \code{IDefinitionHandler} requires the class to implement a \code{Handle} method. Everytime the server receives a \code{textDocument/Definitions} request, this \code{Handle} method will be called. The parameter and return types are specific per request. Goto Definition would pass a textdocument location as input, namely the cursor position, and it expects a \code{LocationLink} as response, namely where the cursor should jump to. Own requests can be realized according to chapter \ref{chapter:customlspmsg} by defining an own interface. \\

All handlers require two additional methods, aside the actual \code{Handle}:
\begin{itemize}
    \item GetRegistrationOptions: Is called when the handler is registred. It allows to set a document selector. This is, that the handler is only active for '.dfy' files.
    \item SetCapability: Allows to set handler-specific capabilities, such as if the rename-handler will also support a 'prepare rename' feature.
\end{itemize}
The code for these methods is always identical and was thus extracted to a generic base class. The generic type parameter refers to the kind of cabability, necessary for the \code{SetCapability} method. This could be, for example, \code{RenameCapability} which has the metnioned bool property about the preparation support.\\

To keep all this boilerplate code separated from the core logic, the actual \code{Handle} method will in most cases just create a provider instance, where all core logic is placed, and forward its result. For example, the full code of handling a compilation looks as shown below.

\begin{lstlisting}[language=csharp, caption={Handling Compilation}, captionpos=b, label={lst:handlecompilation}]
public async Task<CompilerResults> Handle(CompilerParams request, CancellationToken cancellationToken)
{
   _log.LogInformation(string.Format(Resources.LoggingMessages.request_handle, _method));
   try
   {
       FileRepository f = _workspaceManager.GetFileRepository(request.FileToCompile);
       return await Task.Run(() => f.Compile(request.CompilationArguments), cancellationToken);
   }
   catch (Exception e)
   {
       HandleError(string.Format(Resources.LoggingMessages.request_error, _method), e);
       return null;
   }
}
\end{lstlisting}

This is a typical structure of handler. It requests the injected workspace manager for the file and passes it to the core logic provider. Finally, the result is returned as a result. In case of an error, a message is sent to the user and the error is logged within the \code{HandleError} method.\\

Some handlers take additional actions, such as awaiting the result of the provider, and then sending user feedback according to the outcome. This way, the message sending service does not have to be passed downwards to the core logic component.

\subsubsection{Core}
Eigentliche logik. implementiert interface. Die Features ev einzln druch, msus man fast, hat ja vieles interessantes, z.b. so diagnostic conversion (wobie xcdas bei dafny access is)

\subsubsection{Workspace}
The workspace is a component representing any opened files by the client. Thus, it naturally consists only of a single property. This is a dictionary, mapping a file-location to an internal file-representation:

\begin{lstlisting}[language=csharp, caption={Workspace Property}, captionpos=b, label={lst:workspaceproperty}]
private readonly ConcurrentDictionary<Uri, FileRepository> _files
\end{lstlisting}

It offers methods to retrieve files and to update them.  Since updates can be down in two different kinds, incremental or full, the update method is overloaded.

More interesting is the class \code{FileRepository}, which is used as the internal representation of a file. It of course contains the source code. However, this is not done directly as a string property, but wrapped in a class \code{PhysicalFile}. Thus, the actual representation on the hard disk is separated even further. The \code{PhysicalFile} class can then also take responibility for applying file updates.
\intnote{bild hier unbedingt mit workspace -> filerepo -> physfile/translationresult/symobltablemanager und methoden die hier beschrieben werden}.

Aside the file content, each \code{FileRepository} will also contain \code{TranslationResults}. \code{TranslationResults} is a wrapper class for anything provided by the Dafny backend:
\begin{itemize}
    \item Could the file be parsed?
    \item Could it be verified?
    \item Is it logically correct?
    \item What errors and warnings occured?
    \item How far could it be compiled?
    \item What internal compilation results could be produced for later reuse?
\end{itemize}

Last but not least, the newly implemented symbol table is also attached to the file repository. Thus, all information about a file is accessible from within the File Repository. To obtain all of these results, the class simply invokes the \code{SymbolTableGenerator} and the \code{DafnyTranslationUnit}.

\begin{lstlisting}[language=csharp, caption={Handling Compilation}, captionpos=b, label={lst:handlecompilation}]
public interface FileRepository
{
    PhysicalFile PhysicalFile { get; }
    TranslationResult Result { get; }
    ISymbolTableManager SymbolTableManager { get; }
    void UpdateFile(string sourceCodeOfFile);
    void UpdateFile(Container<TextDocumentContentChangeEvent> changes);
}
\end{lstlisting}


\subsubsection{DafnyAccess}
Dafny Access it the package invoking the Dafny backend to obtain verification results. The core class in this package is the \code{DafnyTranslationUnit}. It was partially taken over from the preexisting projects, but as part of this bachelor thesis it was refactored and simplified.

In the constructor, the translation unit accepts a \code{PhysicalFile}. The class then offers a single public method \code{public TranslationResults Verify()}. Within the method, the following sequence of events occurs:
\begin{enumerate}
    \item It is checkd that the instance has never been used before. This is, since the error reporter must be empty. Otherwise, errors would be reported multiple times.
    \item Next, Dafny is configured. This includes the registration of the Dafny error reporter and setting any options to default. The only non-default option is that the engine is supposed to generate a model file, which can later be used for counter example calculation. The configuration is shown in \ref{lst:setupdafnyoptions}.
    \item The Dafny parser is called. This step will report any syntax errors.
    \item The Dafny Resolver is called, if parsing was successful. This step will do semantic checks, such as type checks.
    \item If successful, the precompiled \code{DafnyProgram} will be split into \code{BoogieProgram}s.
    \item The Boogie Execution Engine is invoked to perform logical correctness checks on the \code{BoogieProgram}s.
    \item Any errors that were reported are collected, converted and provided in the field \code{\_diagnosticElements}
    \item All results are wrapped by the \code{TranslationResult} class, providing the diagnostics, the dafny program and the boogie programs. Also, within the property \code{TranslationStatus}, it is remarked how far the verification and translation process succeeded.
\end{enumerate}

\intnote{evtl bild, so ablaufdiagramm}
\intnote{bild mit TranlsationResult + TranlsationStatus wäre gut ich denke}



\begin{lstlisting}[language=csharp, caption={Setting up Dafny Options}, captionpos=b, label={lst:setupdafnyoptions}]
private void SetUpDafnyOptions()
{
    DafnyOptions.Install(new DafnyOptions(_reporter));
    DafnyOptions.Clo.ApplyDefaultOptions();
    DafnyOptions.O.ModelViewFile = FileAndFolderLocations.modelBVD;

}
\end{lstlisting}


\subsection{Symbol Table}
This package provides four components:
\begin{itemize}
    \item Symbol Information
    \item Symbol Table Generation
    \item Symbol Table Navigation
    \item Symbol Table Management
\end{itemize}

\textbf{Symbol Information}
This is a component that summarizes all information about a symbol. Aside the name, this also includes the location, the parent, the declaration, children, and so forth. The class contains a lot of properties, but in exchange, it provides any information that is required. The most important properties are:
\begin{itemize}
    \item Name
    \item File
    \item Position in File
    \item Body Size, if any
    \item Kind and Type
    \item Link to Parent Symbol
    \item Link to Declaration Symbol
    \item Hash with all Children Symbols (Only Declarations)
    \item List with all Descendants (Any symbol occuring in the body)
    \item List with all Usages of the symbol
    \item BaseClasses
    \item The associated module
    \item Link to the associated default class for quick access.
\end{itemize}
The provided properties are supposed to make work with the symbols as comfortable as possible. For example, if a symbol's definition cannot be found, the proeprty with the associated default class can be used to search the symbol there. This is convenient, since the default class is in the global namespace and not a direct ancestor of a symbol.

Technically, the symbol table is more a tree, then table. The data structure is double linked. Each symbol knows about its descendants, but also about its ancestor. Navigating to either one can thus be done in O(1). If the name of a descendant is known, navigating to the symbol can also be done in O(1) due to the hash map. For exmaple, if a module 'M' contains a class 'C', and within the class there is a method 'foo', one can simply start from the root symbol and navigate through the hash maps. The \code{[]} was overloaded to make this as convenient as possible:\\
\code{rootSymbol["M"]["C"]["foo"]}.\\

While this is very fancy, the convenience comes at a price. Many properties do not apply for all kinds of symbol. Consider the following code segment:

\begin{lstlisting}[language=dafny, caption={Example Code Regarding Symbol Information}, captionpos=b, label={lst:aldbkajds}]
method foo() {
    var x := 5;
    print x;
}
\end{lstlisting}

The symbol 'foo' profits by almost all properties. It can have children (the variable x), it has some parent, it can be used. Since foo is a method declaration, the declaration porperty of the symbol does not make sense. In this case, it actually just points to itself. The declaration of x in the second line will have many null values within the symbol information. While the parent is foo, it can not have any children. Since it is a variable definiton, it can have usages though. The final usage of x in the last line (which we also consider a symbol), does not even have usages, since it is a usage itself. Thus many properties are just null for that symbol.

As a consequence, operating on the symbol table must be done with possible null reference expections in mind.

Aside the properties, the \code{SymbolInformation} also offers a public method. This method will check if a certain location is wrapped by the symbol. This namely answers the question, if for example line 5, column 2 is within the symbol's body.

\textbf{Symbol Table Creation}
The symbol table generator accepts a precompiled dafny program in the constructor. It should be available after the dafny translation unit has been executed. The generator offers a public method \code{GenerateSymbolTable}. IT will then first of all create a virtual root symbol. Any other symbols will be attached to the root node as descendants. The root node is also the final return value.\\

Then, all modules (similar to \Csharp or C++ namespaces) will be extracted out of the dafny program. The modules will be sorted by depth, so that top level modules will be treated first and nested modules can be attched properly later on.

Once the modules are sorted by depth, the algorithm iterates over each of the modules. The proper parent symbol will be extracted. For a top level module, this is just the root symbol. Otherwise, for nested modules, the parent module will be located. Finally, the module will accept the declaration visitor. The visitor is described later. Once it completed, all declarations are registred in the symbol table. A second iteration is then started, using the deep visitor, which will ignore delcarations but run through all method bodies and take care of symbol usages.

\textbf{Visitor}
As already mentioned, the whole symbol table generation is realized using the visitor pattern. For that, Dafny code had to be adjusted to offer a \code{Accept(Visitor v)} metod. This method will basically just navigate through the internal dafny symbol representation. For example, when visiting a method, one would like to register the method itself. This is done by the expression \code{v.Visit(this)}. However, the method also contains an ensures statement, which may contain variables or such. Thus, all statements within the 'ensures' clause have to be visited. The Accept-Method will now just forward the call, using \code{foreach (var e in this.EnsureExpressions) {e.Accept(v)}}. The same applies for method parameters and other items like the requires clause. Finally, the body of the method is to visit using \code{foreach (var stmt in this.Body) {stmt.Accept(v)}}. Once everything is done, the scope of the method is left by calling \code{v.Leave(this)}.\\

If you recall the last section, it was said that two runs are actually performed. One to capture all declarations, and one to visit all method bodies. Thus, the visitor is having a boolean \code{GoesDeep}, which decideds if bodies like occuring at a method are visited at all. The final Accept method for a method looks as shown below. The method is shortened, there are more clauses like for example the requires clause.


\begin{lstlisting}[language=csharp, caption={Accepting a Visitor}, captionpos=b, label={lst:visitoraccept}]
public override void Accept(Visitor v)
{
  v.Visit(this);
  if (v.GoesDeep)
  {
    foreach (var ens in this.Ens)
    {
      ens.Accept(v);
    }        
    foreach (var stmt in this.Body.Body)
    {
      stmt.Accept(v);
    }
  }
  v.Leave(this);
}
\end{lstlisting}
Note that the method is marked with the override keyword. This is, since every AST-Element is either a statement or an expression, among others. In case we left out a speicific AST element, just a general accept method is defined for statements, as well as expressions. However, for AST elements that we support, a more specific method is supposed to be used. (hmm abschnitt weg? is gebrabbel)

On the other hand of the visitor, there is the actual Visitor. The visitor now has to implement \code{Visit} methods for each of the AST elements that it is supposed to visit, for example our \code{Method} from the preceding example.\\

The Visitor itself will now actually build up the symbol table. For that, it stores the current scope in a property. For example, when visiting a method, the parent scope is always some kind of class that was visisted before. When the method is finally visisted, the property 'parent' can just be set with the scope the visitior is in. Since the method itself will have it's own body, the new scope can then be set to a method. This will attach all symbols to the method. Once the method is done, \code{Leave()} is called, which will reset the scope to the class.\\

The Visit method of the first visitor, which only takes care of declarations, will itself just create a symbol, and attach it to the current scope. All required information can be taken from the AST element that is visited. This includes the name, the position, and so on.\\

\begin{lstlisting}[language=csharp, caption={Visiting a Method}, captionpos=b, label={lst:visitorvisit1}]
public override void Visit(Method o)
{
    var symbol = CreateSymbol(
        name: o.Name,
        kind: Kind.Method,

        positionAsToken: o.tok,
        bodyStartPosAsToken: o.BodyStartTok,
        bodyEndPosAsToken: o.BodyEndTok,

        isDeclaration: true,
        declarationSymbol: null,
        addUsageAtDeclaration: false,

        canHaveChildren: true,
        canBeUsed: true
    );
    SetScope(symbol);
}
\end{lstlisting}

The \code{CreateSymbol} method will set all properties accordingly. That means, a symbol that can have children will be initialized with a list for children, while a symbol that cannot have children will just have a null entry there. Note that the scope of the visitor is set to the method for future visitations.

The second visitor will also visit declarations, but no longer create a symbol for them. Instead, just the proper scope will be set. The second visitor will now also visit method bodies. Within the body, it will encounter local variables. These were not caught by the first visistor, but this is ok, since local variables are not accessible before they weren't declared.  Furthermore, symbol usages such as method calls or variable usages are now encountered. The visitor now has the responsibility, to create proper symbols for these. Since these are symbol usages, it is not sufficient to just create a symbol and attach it to the parent scope. The following additional tasks have ot be done:
\begin{itemize}
    \item Where am i declared?
    \item Add usage to my declaration
\end{itemize}

To find the declaration, the symbol table navigator can already be used. It is discussed below. The navigator will just iterate from parent to parent and will return the first symbol, that is a declaraiton, and matches the name. Challenges occured when a symbol is defined in global scope or in a base class. Both difficulties were resolved by adding separate checks for them.

Once the declaration is found, it is simple to add the just newly created symbol as one of the declaration's usages.

The tricky cast is indeed to find a symbols declaration, which could be extracted to the navigator:

\begin{lstlisting}[language=csharp, caption={Finding a Declaration}, captionpos=b, label={lst:visitorfinddecl}]
protected ISymbol FindDeclaration(string target, ISymbol scope, Kind kind)
{
    INavigator navigator = new SymbolTableNavigator();
    bool filter(ISymbol s) => s.Name == target && s.IsDeclaration && s.Kind == kind;
    return navigator.BottomUpFirst(scope, filter);
}
\end{lstlisting}
This snippet assigns the navigator to move upwards in scope and serach for a symbol, that is a declaration and matches in name and kind. If found, the proper symbol must be the according declaration.

\textbf{Symbol Table Navigator}
To operate on the (partially) constructed symbol table, a separate component to navigate was created. It has basically two procedures. Remember that the data structure of the symbol table is basically a double linked tree.

\begin{itemize}
\item TopDown: Starting from a node, the navigator dives downwards and searches a specific symbol.
\item BottomUp: Starting from a node, the navigator moves upwards the tree and searches a specific symbol.
\end{itemize}

\intnote{2do Bild von nem baum und dann wie es so hoch und runter geht, Beispiel, Visualisierung einbauen fuer die Laufzeitanalyse.} \\

Both options are implemented so that they can return a single, first match, or any symbols that match a criterion. To illustrate this, let's have a look at two examples.
\begin{itemize}
    \item You want to know what symbol is at the cursor position. You call \code{TopDown} and pass the rootSymbol, as well as the cursor position as arguments. The rootSymbol hast 3 modules attached to it. One ranging from line 1 to 20, another ranging from line 21 to 40. The algorithm will now decide, in which of the two modules a further search is worthwile. If the cursor is located at line 25, it will continue to search in the second module. This can simply be done by calling the same function recursively, handing the second module as the entry point for the recursive search. Within the recursive call, the proper class will be found, and so on. Default namespaces and default clases had to be treated separately for this case.
    \item To build up autocompletion suggestions, you want to know what declarations are available at the symbol you found just before. Thus, you navigate to the parent symbol, and then you collect all children of that symbol. Then, again, go to the next parent and continue like that until the rootSymbol is reached. Again, the problem can be solved using recursion.
\end{itemize}
Note that this navigation can be executed very fast.

\textbf{Symbol Table Manager}
The manager is a rather simple component and can be used as an access point for the user of the symbol table. It is constructed by handing over a root symbol of a fully generated symbol table. It then offers methods such as \code{ISymbol GetSymbolByPosition(Uri file, int line, int character)}. That method will then just create a navigator and use the (maybe rather complex navigator) to provide the user with the desired result. 



%%%%%%%%%%%%%%%folgendes nach results


\textbf{Symbol Table Runtime -> Results}

\intnote{aufbau runtime}
\intnote{warum steht schon oben was von O(1) wenn hier runtime kommt?}

The features themselves are primarily based on the symbol table.
In particular auto completion, go to definition, CodeLens, hover information and rename. \\

Due to the structure of our Symbol table (which is updated after every change in a Dafny file)
the basic information is provided by references.
Each symbol carries references to its child simbols, to the parent symbol, to the original declaration and much more information.
All these references were prepared when the symbol table was created. You can therefore call them immediately (runtime O(1)).  \intnote{Das steh talles schon oben...}

The difficulty lies in finding the "entry symbol".

The navigation component described above is used for this. The system uses the cursor position to find the deepest symbol that encloses the cursor position. This symbol is the entry point. And to find this symbol, the longest runtime is required for the features - apart from the creation of the actual symbol table of course.

\textbf{Feature Support -> nach results (früher so, jetzt so, jetzt voll geil dank key value)}

Split in creation, manageing, navigation
Symbol eigenes teil.
properties aufzeigen


Since we have object information (and not just strings anymore) with our self-written symbol table,
the whole position to string parsing was dropped. \\

In our old version we had to find out from the current cursor position which word in the code could be meant.
Then we iterated over the whole symbol table and checked if there was a symbol with the same string as name.
The first match was looked at as a meant symbol. \\

Our new design eliminates all of this effort and avoidable assumptions.
We access the currently marked symbol directly via the position data.
String comparisons and corresponding string extractions are completely eliminated.
This leads to better performance and above all to reliable symbol references.

To enable efficient access to the entry points, we have opted for a key-value data structure. The key is the child symbol's name, the value the actual \code{SymbolInformation} object.
This hash structure enables us to access child symbols with a runtime of O(1). Since every symbol also has a link to it's parent, navigation in both ways can be done within O(1).

2do hier noch etwas genauer drauf eingehen... visualisieren... hash besser begruenden. Naja finds eig gut. steht ja da dass der grund O1 ist.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Testing}
ich glaub hier kann man unit tests übernehemn.
intergration kurz neu schreiben
system test auch nur kurz, mimi, ist weg.


\subsection{Code Reviews}
\intnote{ich glaube es ist nicht gedacht einzelne code reviews zu dokumentieren. das waere ja mehr dann wie ein arbbeitsrapport, aka woche 12: wir haben das code review bearbeitet und dies und das gemacht. eher so bei kapitel design: wir haben entschieden, strings da und da auszulagnern. dies wurde u.a. wegen dem code review so geamcht. dann implementation: hier wurde das so und so implementiert, weil beim code review es so gesagt wurde}
Fabians Feedback aus der SA... neues Review. "Tu Gutes und sprich davon".

\subsubsection{Client Code Review}
After a joint code review together with our advisors, individual optimisation potential was identified.
This subchapter describes the associated improvements to the architecture. \\

Although interfaces were used for the individualized types,
the individual core components did not use their own interfaces.
To reduce coupling, isolated modules were formed in a comprehensive refactoring process.
The modules now no longer program on the class implementations, but against the interface. \\

For this purpose one importable module with the name \code{\_<Directory>Modules} was created for each directory.
Figure \ref{fig:client_2nd_refactoring} shows an overview of the interfaces.
In addition, the dependencies among each other are shown.
For simplicity, the contents of \code{stringRessources} and \code{typeInterfaces} have been omitted. \\

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{client_2nd_refactoring.png}
    \caption{Second Major Client Refactoring}
    \label{fig:client_2nd_refactoring}
\end{figure}

At first glance, the architecture appears much tidier.
The dependencies are now pointing from top to bottom.
Methods have been simplified and the number of parameters could be reduced significantly.
Component identifiers have been renamed to be more understandable. \\

However, it is now also noticeable that there are considerably more dependencies on \code{stringRessources}.
While in the previous version only the module \code{ui} used \code{stringResources}, it is now used by almost all other modules.

This has the following reason: Up until this refactoring, the task of \code{stringResources} was to be a central collection of all UI strings. \glsadd{UI}
In the code review, it was decided that default values should no longer be set within the independent modules,
but rather at a central location.
This would make it easier to maintain these values. \\



\textbf{m}
\textbf{m}
\textbf{m}
\textbf{m}
\textbf{m}
\textbf{m}



\subsection{Usability Test --> auch results oder?}


\subsection{Mono Support for macOS and Linux -Kaptitel nicht hier. entweder anaylse oder Result}
Eines der Kernzeiele war es, Support fuer mehrere Plattformen zu bieten. Dh nebst Windows auch macOS und Linux.
Da wir in unserer SA von Core auf Framework umsteigen musste, stand fest, dass wir mono fuer den Support auf Linux und macOS brauchen.
(warum in der SA; plficht wegen dafny core. was ist mono)

Leider funktionierts nicht.
Anssaetze die wir probiert haben. verschiedene mono versionen, angefragt im slack. antwort erhalten?
github issues: allgemein probleme mit lunux/mac weil primaer auf windows und gar nicht auf mac getestet wird. (heikle aussage selbs tmit quelle)

\cite{sa}
\cite{mono-slack}
\cite{mono-git}
